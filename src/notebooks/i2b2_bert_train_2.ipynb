{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flair\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/e3/389c2dd8d0e6ca1d8fad11aa4940e8df6909a26a5d954c0eff01f0d78b57/flair-0.4.3-py3-none-any.whl (180kB)\n",
      "\u001b[K     |████████████████████████████████| 184kB 879kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: mpld3==0.3 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (0.3)\n",
      "Collecting hyperopt>=0.1.1 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/c5/4b57fb376d24127b2960678ef98307fac1c6fb7a2ace7f67971949dd6b56/hyperopt-0.2.1-py3-none-any.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 37.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting deprecated>=1.2.4 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/88/0e/9d5a1a8cd7130c49334cce7b8167ceda63d6a329c8ea65b626116bc9e9e6/Deprecated-1.2.6-py2.py3-none-any.whl\n",
      "Collecting segtok>=1.5.7 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/1d/59/6ed78856ab99d2da04084b59e7da797972baa0efecb71546b16d48e49d9b/segtok-1.5.7.tar.gz\n",
      "Collecting urllib3<1.25,>=1.20 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/01/11/525b02e4acc0c747de8b6ccdab376331597c569c42ea66ab0a1dbd36eca2/urllib3-1.24.3-py2.py3-none-any.whl (118kB)\n",
      "\u001b[K     |████████████████████████████████| 122kB 39.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pytorch-transformers>=1.1.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (1.1.0)\n",
      "Collecting ipython==7.6.1 (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/2c/c7d44277b599df35af734d8f4142d501192fdb7aef5d04daf882d7eccfbc/ipython-7.6.1-py3-none-any.whl (774kB)\n",
      "\u001b[K     |████████████████████████████████| 778kB 28.0MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (4.36.1)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (3.1.1)\n",
      "Requirement already satisfied: sklearn in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (0.0)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (3.8.1)\n",
      "Collecting sqlitedict>=1.6.0 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/1c/c757b93147a219cf1e25cef7e1ad9b595b7f802159493c45ce116521caff/sqlitedict-1.6.0.tar.gz\n",
      "Requirement already satisfied: pytest>=3.6.4 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (5.2.0)\n",
      "Collecting bpemb>=0.2.9 (from flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/bc/70/468a9652095b370f797ed37ff77e742b11565c6fd79eaeca5f2e50b164a7/bpemb-0.3.0-py3-none-any.whl\n",
      "Requirement already satisfied: regex in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (2019.8.19)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (0.2.0)\n",
      "Collecting langdetect (from flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/59/59/4bc44158a767a6d66de18c4136c8aa90491d56cc951c10b74dd1e13213c9/langdetect-1.0.7.zip (998kB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 46.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tabulate in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (0.8.5)\n",
      "Requirement already satisfied: torch>=1.1.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from flair) (1.2.0)\n",
      "Collecting bson (from hyperopt>=0.1.1->flair)\n",
      "  Downloading https://files.pythonhosted.org/packages/b9/42/e823b5f13515e3af308fb6efcacff456fc59078ec0e9ac426e842d66c9cb/bson-0.5.8.tar.gz\n",
      "Requirement already satisfied: scipy in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.3.1)\n",
      "Requirement already satisfied: numpy in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.17.2)\n",
      "Collecting networkx==2.2 (from hyperopt>=0.1.1->flair)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f3/f4/7e20ef40b118478191cec0b58c3192f822cace858c19505c7670961b76b2/networkx-2.2.zip (1.7MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7MB 41.3MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.12.0)\n",
      "Requirement already satisfied: cloudpickle in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (1.2.2)\n",
      "Requirement already satisfied: future in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from hyperopt>=0.1.1->flair) (0.17.1)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from deprecated>=1.2.4->flair) (1.11.2)\n",
      "Requirement already satisfied: sentencepiece in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytorch-transformers>=1.1.0->flair) (0.1.83)\n",
      "Requirement already satisfied: requests in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytorch-transformers>=1.1.0->flair) (2.22.0)\n",
      "Requirement already satisfied: boto3 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytorch-transformers>=1.1.0->flair) (1.9.243)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from ipython==7.6.1->flair) (2.0.10)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from ipython==7.6.1->flair) (4.3.3)\n",
      "Requirement already satisfied: decorator in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from ipython==7.6.1->flair) (4.4.0)\n",
      "Requirement already satisfied: backcall in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.1.0)\n",
      "Requirement already satisfied: pickleshare in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.7.5)\n",
      "Requirement already satisfied: pygments in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from ipython==7.6.1->flair) (2.4.2)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from ipython==7.6.1->flair) (0.15.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from ipython==7.6.1->flair) (40.8.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from ipython==7.6.1->flair) (4.7.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.8.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (2.4.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from sklearn->flair) (0.21.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from gensim>=3.4.0->flair) (1.8.4)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (1.3.0)\n",
      "Requirement already satisfied: pluggy<1.0,>=0.12 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (0.13.0)\n",
      "Requirement already satisfied: wcwidth in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (0.1.7)\n",
      "Requirement already satisfied: importlib-metadata>=0.12; python_version < \"3.8\" in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (0.23)\n",
      "Requirement already satisfied: packaging in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (19.2)\n",
      "Requirement already satisfied: more-itertools>=4.0.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (7.2.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (19.2.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pytest>=3.6.4->flair) (1.8.0)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from requests->pytorch-transformers>=1.1.0->flair) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from requests->pytorch-transformers>=1.1.0->flair) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from requests->pytorch-transformers>=1.1.0->flair) (2.8)\n",
      "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from boto3->pytorch-transformers>=1.1.0->flair) (0.2.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.243 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from boto3->pytorch-transformers>=1.1.0->flair) (1.12.243)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from boto3->pytorch-transformers>=1.1.0->flair) (0.9.4)\n",
      "Requirement already satisfied: parso>=0.5.0 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from jedi>=0.10->ipython==7.6.1->flair) (0.5.1)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from pexpect; sys_platform != \"win32\"->ipython==7.6.1->flair) (0.6.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from scikit-learn->sklearn->flair) (0.14.0)\n",
      "Requirement already satisfied: boto>=2.32 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim>=3.4.0->flair) (2.49.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from importlib-metadata>=0.12; python_version < \"3.8\"->pytest>=3.6.4->flair) (0.6.0)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /opt/.pyenv/versions/3.7.4/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.243->boto3->pytorch-transformers>=1.1.0->flair) (0.15.2)\n",
      "Building wheels for collected packages: segtok, sqlitedict, langdetect, bson, networkx\n",
      "  Building wheel for segtok (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for segtok: filename=segtok-1.5.7-cp37-none-any.whl size=23258 sha256=43bf4c00761fb6d954bf078509f826668b27fb1a94b9aaab4219daa828cee05c\n",
      "  Stored in directory: /root/.cache/pip/wheels/15/ee/a8/6112173f1386d33eebedb3f73429cfa41a4c3084556bcee254\n",
      "  Building wheel for sqlitedict (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sqlitedict: filename=sqlitedict-1.6.0-cp37-none-any.whl size=14690 sha256=e07cf76df737b88a5ff0579abc9d383f8ed232e6f12cecda7d0f194faccae4e4\n",
      "  Stored in directory: /root/.cache/pip/wheels/bd/57/d3/907c3ee02d35e66f674ad0106e61f06eeeb98f6ee66a6cc3fe\n",
      "  Building wheel for langdetect (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for langdetect: filename=langdetect-1.0.7-cp37-none-any.whl size=993459 sha256=875a8481770c296d493e0ecf6f21f2c15ae0040f6e64d6d5d7ef2b5301222d41\n",
      "  Stored in directory: /root/.cache/pip/wheels/ec/0c/a9/1647275e7ef5014e7b83ff30105180e332867d65e7617ddafe\n",
      "  Building wheel for bson (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bson: filename=bson-0.5.8-cp37-none-any.whl size=11950 sha256=1e01c3a402e91ed678d87f88c4947d73915664209d612bb009df77ac12d74537\n",
      "  Stored in directory: /root/.cache/pip/wheels/78/c8/73/5d5234df5208c21532b0a536776d7cbce9c9216b5776213dd4\n",
      "  Building wheel for networkx (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for networkx: filename=networkx-2.2-py2.py3-none-any.whl size=1527322 sha256=9cb5d5d879aba864377e8144d1c27c5534e7e9d5416b4e1b58620338393fb1f8\n",
      "  Stored in directory: /root/.cache/pip/wheels/68/f8/29/b53346a112a07d30a5a84d53f19aeadaa1a474897c0423af91\n",
      "Successfully built segtok sqlitedict langdetect bson networkx\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement Cython==0.29.12, but you'll have cython 0.29.13 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement h5py==2.9.0, but you'll have h5py 2.10.0 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement nltk==3.2.5, but you'll have nltk 3.4.5 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement numpy==1.16.4, but you'll have numpy 1.17.2 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement scikit-learn==0.21.2, but you'll have scikit-learn 0.21.3 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement scipy==1.3.0, but you'll have scipy 1.3.1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: deeppavlov 0.6.1 has requirement tqdm==4.32.2, but you'll have tqdm 4.36.1 which is incompatible.\u001b[0m\n",
      "Installing collected packages: bson, networkx, hyperopt, deprecated, segtok, urllib3, ipython, sqlitedict, bpemb, langdetect, flair\n",
      "  Found existing installation: networkx 2.3\n",
      "    Uninstalling networkx-2.3:\n",
      "      Successfully uninstalled networkx-2.3\n",
      "  Found existing installation: urllib3 1.25.6\n",
      "    Uninstalling urllib3-1.25.6:\n",
      "      Successfully uninstalled urllib3-1.25.6\n",
      "  Found existing installation: ipython 7.8.0\n",
      "    Uninstalling ipython-7.8.0:\n",
      "      Successfully uninstalled ipython-7.8.0\n",
      "Successfully installed bpemb-0.3.0 bson-0.5.8 deprecated-1.2.6 flair-0.4.3 hyperopt-0.2.1 ipython-7.6.1 langdetect-1.0.7 networkx-2.2 segtok-1.5.7 sqlitedict-1.6.0 urllib3-1.24.3\n",
      "\u001b[33mWARNING: You are using pip version 19.2.3, however version 19.3 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flair"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVIDIA/apex ./packages/apex && cd ./packages/apex && pip install -v --no-cache-dir \\\n",
    "    --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-DGXS-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda')\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "for i in range(n_gpu):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logger import initialize_logger\n",
    "logger = initialize_logger('../workdir/logs/i2b2_active_learning.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = '../workdir/models/0.4.0'\n",
    "\n",
    "# MAX_LEN = 150\n",
    "MAX_LEN = 100\n",
    "\n",
    "#BATCH_SIZE = 105\n",
    "#BATCH_SIZE = 45 \n",
    "BATCH_SIZE = 32\n",
    "\n",
    "PRED_BATCH_SIZE = 1200\n",
    "\n",
    "random_state = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.datasets import ColumnCorpus\n",
    "\n",
    "from bert_utils import train, test, create_model_optimizer, create_tensors, prepare_flair_corpus_for_bert, to_torch_tensors\n",
    "from bert_utils import make_bert_tag_dict_from_flair_corpus\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from pytorch_transformers import BertTokenizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from flair.datasets import ColumnCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 20:00:54,453 Reading data from ../workdir/genia/conll\n",
      "2019-08-21 20:00:54,454 Train: ../workdir/genia/conll/Genia4ERtask1.iob2\n",
      "2019-08-21 20:00:54,454 Dev: None\n",
      "2019-08-21 20:00:54,455 Test: ../workdir/genia/conll/Genia4EReval1.iob2\n",
      "{\n",
      "    \"TRAIN\": {\n",
      "        \"dataset\": \"TRAIN\",\n",
      "        \"total_number_of_documents\": 16691,\n",
      "        \"number_of_documents_per_class\": {},\n",
      "        \"number_of_tokens_per_tag\": {},\n",
      "        \"number_of_tokens\": {\n",
      "            \"total\": 443221,\n",
      "            \"min\": 2,\n",
      "            \"max\": 204,\n",
      "            \"avg\": 26.55449044395183\n",
      "        }\n",
      "    },\n",
      "    \"TEST\": {\n",
      "        \"dataset\": \"TEST\",\n",
      "        \"total_number_of_documents\": 3856,\n",
      "        \"number_of_documents_per_class\": {},\n",
      "        \"number_of_tokens_per_tag\": {},\n",
      "        \"number_of_tokens\": {\n",
      "            \"total\": 101039,\n",
      "            \"min\": 2,\n",
      "            \"max\": 208,\n",
      "            \"avg\": 26.203060165975103\n",
      "        }\n",
      "    },\n",
      "    \"DEV\": {\n",
      "        \"dataset\": \"DEV\",\n",
      "        \"total_number_of_documents\": 1855,\n",
      "        \"number_of_documents_per_class\": {},\n",
      "        \"number_of_tokens_per_tag\": {},\n",
      "        \"number_of_tokens\": {\n",
      "            \"total\": 49330,\n",
      "            \"min\": 2,\n",
      "            \"max\": 150,\n",
      "            \"avg\": 26.59299191374663\n",
      "        }\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# data_folder = '../workdir/i2b2/conll/'\n",
    "# #attr = 'hypertension'\n",
    "# attr = 'diabetes'\n",
    "# #attr = 'cad'\n",
    "# corpus = ColumnCorpus(data_folder, {0 : 'text', 1 : 'ner'},\n",
    "#                       train_file=f'i2b2_training_{attr}.conll',\n",
    "#                       test_file=f'i2b2_testing_{attr}.conll',\n",
    "#                       dev_file=None)\n",
    "\n",
    "\n",
    "data_folder = '../workdir/genia/conll/'\n",
    "attr = 'genia'\n",
    "corpus = ColumnCorpus(data_folder, \n",
    "                      {0 : 'text', 1 : 'ner'},\n",
    "                      train_file='Genia4ERtask1.iob2',\n",
    "                      test_file='Genia4EReval1.iob2',\n",
    "                      dev_file=None)\n",
    "\n",
    "print(corpus.obtain_statistics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N with more than max lengths: 18\n",
      "Ratio: 0.0010784254987717932\n"
     ]
    }
   ],
   "source": [
    "lengths = np.array([len(sent) for sent in corpus.train])\n",
    "n_max_lengths = (lengths > (MAX_LEN-2)).sum()\n",
    "print('N with more than max lengths:', n_max_lengths)\n",
    "print('Ratio:', n_max_lengths / lengths.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bpe_tokenizer = BertTokenizer.from_pretrained('bert-base-cased', cache_dir=CACHE_DIR, do_lower_case=False)\n",
    "tags_vals, tag2idx = make_bert_tag_dict_from_flair_corpus(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_corpus = prepare_flair_corpus_for_bert(corpus, bpe_tokenizer, max_length=MAX_LEN)\n",
    "numpy_tensors = {name : create_tensors(bpe_tokenizer, tag2idx, sub_corp[0], sub_corp[1], MAX_LEN)\n",
    "                 for name, sub_corp in bert_corpus.items()}\n",
    "\n",
    "torch_tensors = {name : to_torch_tensors(tensors) \n",
    "                 for name, tensors in numpy_tensors.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 20:01:14,741 - biomed_ie - INFO - Full finetuning: True\n",
      "2019-08-21 20:01:14,744 - biomed_ie - INFO - N parameters: 108321807\n"
     ]
    }
   ],
   "source": [
    "model, optimizer, lr_scheduler = create_model_optimizer(tag2idx, \n",
    "                                                        cache_dir=CACHE_DIR,\n",
    "                                                        full_finetuning=True, \n",
    "                                                        base_lr=5e-5,\n",
    "                                                        bert_model='../workdir/bio_bert/torch2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sequence_tagger_bert import SequenceTaggerBert\n",
    "\n",
    "seq_tagger = SequenceTaggerBert(model, bpe_tokenizer, tags_vals, tag2idx)\n",
    "\n",
    "def prepare_corpus(corpus):\n",
    "    return ([[token.text for token in sent.tokens] for sent in corpus], \n",
    "            [[token.tags['ner'].value for token in sent.tokens] for sent in corpus])\n",
    "\n",
    "def prep_tens(tokens, labels):\n",
    "    bpe_tokens, max_len, token_ids, token_masks, bpe_masks = seq_tagger._make_tokens_tensors(tokens, seq_tagger._max_len)\n",
    "    label_ids, loss_masks = seq_tagger._make_label_tensors(labels, bpe_masks, max_len)\n",
    "    mask_sum = token_masks[loss_masks].sum()\n",
    "    return token_ids, label_ids\n",
    "\n",
    "torch_tensors = {'train' : prep_tens(*prepare_corpus(corpus.train)),\n",
    "                 'test' : prep_tens(*prepare_corpus(corpus.test)),\n",
    "                 'dev' : prep_tens(*prepare_corpus(corpus.dev))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info('Creating model...')\n",
    "torch.cuda.empty_cache()\n",
    "# model, optimizer, lr_scheduler = create_model_optimizer(tag2idx, \n",
    "#                                                         cache_dir=CACHE_DIR,\n",
    "#                                                         full_finetuning=True, \n",
    "#                                                         base_lr=5e-5)\n",
    "\n",
    "\n",
    "logger.info('Done.')\n",
    "\n",
    "train_data = TensorDataset(*torch_tensors['train'])\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, \n",
    "                              batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_data = TensorDataset(*torch_tensors['dev'])\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, \n",
    "                              batch_size=PRED_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train(model, optimizer, lr_scheduler, train_dataloader, valid_dataloader, \n",
    "      epochs=20, tags_vals=tags_vals, early_stopping=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7.301903985164783e-06, 0.7253837318575755)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_data = TensorDataset(*torch_tensors['test'])\n",
    "# test_sampler = SequentialSampler(test_data)\n",
    "# test_dataloader = DataLoader(test_data, sampler=test_sampler, \n",
    "#                              batch_size=PRED_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "def prepare_corpus2(corpus):\n",
    "    return list(zip([[token.text for token in sent.tokens] for sent in corpus], \n",
    "            [[token.tags['ner'].value for token in sent.tokens] for sent in corpus]))\n",
    "\n",
    "collate_fn = lambda inpt: tuple(zip(*inpt))\n",
    "\n",
    "val_dataset = prepare_corpus2(corpus.test)\n",
    "val_sampler = SequentialSampler(val_dataset)\n",
    "val_dataloader = DataLoader(val_dataset, \n",
    "                            sampler=val_sampler, \n",
    "                            batch_size=1200,\n",
    "                            collate_fn=collate_fn)\n",
    "\n",
    "_, loss, f1 = seq_tagger.predict(val_dataloader, evaluate=True)\n",
    "loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-21 18:20:45,613 - biomed_ie - INFO - Evaluate:\n",
      "2019-08-21 18:20:53,372 - biomed_ie - INFO - Validation loss: 3.99536884437664e-06\n",
      "2019-08-21 18:20:53,920 - biomed_ie - INFO - Validation F1-Score: 0.7184764733966368\n",
      "2019-08-21 18:20:53,921 - biomed_ie - INFO - Validation accuracy: 0.9350969208679004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3.99536884437664e-06, 0.7184764733966368)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = TensorDataset(*torch_tensors['test'])\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_dataloader = DataLoader(test_data, sampler=test_sampler, \n",
    "                             batch_size=PRED_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "logger.info('Evaluate:')\n",
    "test(model, test_dataloader, tags_vals=tags_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), f'../workdir/models/bert/{attr}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_pretrained_bert import BertForTokenClassification\n",
    "\n",
    "BIO_BERT = '../workdir/bio_bert/torch'\n",
    "tags_vals, tag2idx = make_bert_tag_dict_from_flair_corpus(corpus)\n",
    "loaded_model = BertForTokenClassification.from_pretrained(BIO_BERT, num_labels=len(tag2idx))\n",
    "\n",
    "loaded_model.load_state_dict(torch.load(f'../workdir/models/bert/{attr}.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate document level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from i2b2_utils import drop_noise_samples\n",
    "\n",
    "dataset_test_path = '../workdir/i2b2/i2b2_testing.json'\n",
    "dataset_test = pd.read_json(dataset_test_path)\n",
    "dataset_test.head()\n",
    "test_selected_dataset = drop_noise_samples(dataset_test, attr.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "\n",
    "def flair_process_i2b2(model, dataset, attr_name):\n",
    "    res = model.predict([Sentence(t) for t in dataset.texts])\n",
    "    res = [[e.tags[attr_name].value for e in sent] for sent in res]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-06 15:53:14,376 loading file ../models/new/CAD//elmo-pubmed/1.0/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "\n",
    "#model = SequenceTagger.load('../models/new/DIABETES/fasttext/1.0/best-model.pt')\n",
    "#model = SequenceTagger.load('../models/new/HYPERTENSION//elmo-pubmed/1.0/best-model.pt')\n",
    "model = SequenceTagger.load('../models/new/CAD//elmo-pubmed/1.0/best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_results = flair_process_i2b2(model, test_selected_dataset, attr_name)\n",
    "pos, pred_pos, tp = evaluation_level_document(flair_results, test_selected_dataset, attr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from i2b2_utils import evaluation_level_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For bert\n",
    "from bert_utils import annotate_text \n",
    "\n",
    "pred_tags = annotate_text(loaded_model, test_dataloader, tags_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, pred_pos, tp = evaluation_level_document(pred_tags, test_selected_dataset, attr.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.9821428571428571\n",
      "Precision:  0.9553349875930521\n",
      "F1: 0.9685534591194969\n"
     ]
    }
   ],
   "source": [
    "recall = tp / pos\n",
    "precision = tp / pred_pos\n",
    "f1 = 2. * recall * precision / (recall + precision)\n",
    "\n",
    "print('Recall: ', recall)\n",
    "print('Precision: ', precision)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hypertension:\n",
    "Recall:  0.9719387755102041\n",
    "Precision:  0.9645569620253165\n",
    "F1: 0.9682337992376113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAD:\n",
    "Recall:  0.9511111111111111\n",
    "Precision:  0.6793650793650794\n",
    "F1: 0.7925925925925925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diabetes:\n",
    "Recall:  0.9667590027700831\n",
    "Precision:  0.8790931989924433\n",
    "F1: 0.9208443271767809"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BERT Hypertension 0.7452339688041594"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entity-level f1 score 0.7830423940149627 (Diabetes Fast text Biomedical)\n",
    "# Entity-level f1 score 0.7307017543859649 (HYPERTENSION) FastText\n",
    "# Enitty-level f1 score 0.360471645143178 (CAD) fastext"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
