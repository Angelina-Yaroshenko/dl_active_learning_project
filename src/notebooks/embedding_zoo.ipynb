{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing different embeddigs for biomedical sequence labelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///notebook/code/biomed_ie/src/vadim-ml-tools\n",
      "Installing collected packages: vadim-ml\n",
      "  Found existing installation: vadim-ml 0.1.0\n",
      "    Uninstalling vadim-ml-0.1.0:\n",
      "      Successfully uninstalled vadim-ml-0.1.0\n",
      "  Running setup.py develop for vadim-ml\n",
      "Successfully installed vadim-ml\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -e vadim-ml-tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: flair in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (0.4.1)\n",
      "Requirement already satisfied: tinydb in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (3.13.0)\n",
      "Requirement already satisfied: hyperopt in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (0.1.2)\n",
      "Requirement already satisfied: nltk in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (3.4)\n",
      "Requirement already satisfied: allennlp in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (0.8.3)\n",
      "Requirement already satisfied: bpemb>=0.2.9 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (0.2.12)\n",
      "Requirement already satisfied: segtok>=1.5.7 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (1.5.7)\n",
      "Requirement already satisfied: sqlitedict>=1.6.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (1.6.0)\n",
      "Requirement already satisfied: gensim>=3.4.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (3.6.0)\n",
      "Requirement already satisfied: sklearn in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (0.0)\n",
      "Requirement already satisfied: mpld3>=0.3 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (0.3)\n",
      "Requirement already satisfied: regex==2018.1.10 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (2018.1.10)\n",
      "Requirement already satisfied: matplotlib>=2.2.3 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (3.1.0)\n",
      "Requirement already satisfied: deprecated>=1.2.4 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (1.2.5)\n",
      "Requirement already satisfied: pytorch-pretrained-bert>=0.6.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (4.28.1)\n",
      "Requirement already satisfied: torch>=1.0.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flair) (1.1.0)\n",
      "Requirement already satisfied: pymongo in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from hyperopt) (3.8.0)\n",
      "Requirement already satisfied: numpy in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from hyperopt) (1.15.4)\n",
      "Requirement already satisfied: future in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from hyperopt) (0.17.1)\n",
      "Requirement already satisfied: networkx in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from hyperopt) (2.2)\n",
      "Requirement already satisfied: six in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from hyperopt) (1.11.0)\n",
      "Requirement already satisfied: scipy in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from hyperopt) (1.1.0)\n",
      "Requirement already satisfied: singledispatch in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from nltk) (3.4.0.3)\n",
      "Requirement already satisfied: overrides in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (1.9)\n",
      "Requirement already satisfied: pytz>=2017.3 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (2018.7)\n",
      "Requirement already satisfied: responses>=0.7 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (0.10.6)\n",
      "Requirement already satisfied: conllu==0.11 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (0.11)\n",
      "Requirement already satisfied: awscli>=1.11.91 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (1.16.161)\n",
      "Requirement already satisfied: moto>=1.3.4 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (1.3.8)\n",
      "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (0.12.1)\n",
      "Requirement already satisfied: editdistance in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (0.5.3)\n",
      "Requirement already satisfied: pytest in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (4.5.0)\n",
      "Requirement already satisfied: ftfy in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (5.5.1)\n",
      "Requirement already satisfied: unidecode in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (1.0.23)\n",
      "Requirement already satisfied: boto3 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (1.9.59)\n",
      "Requirement already satisfied: flaky in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (3.5.3)\n",
      "Requirement already satisfied: numpydoc>=0.8.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (0.9.1)\n",
      "Requirement already satisfied: h5py in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (2.8.0)\n",
      "Requirement already satisfied: requests>=2.18 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (2.20.1)\n",
      "Requirement already satisfied: msgpack<0.6.0,>=0.5.6 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (0.5.6)\n",
      "Requirement already satisfied: flask>=1.0.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (1.0.3)\n",
      "Requirement already satisfied: sqlparse>=0.2.4 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (0.3.0)\n",
      "Requirement already satisfied: tensorboardX>=1.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (1.4)\n",
      "Requirement already satisfied: parsimonious>=0.8.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (0.8.1)\n",
      "Requirement already satisfied: word2number>=1.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (1.1)\n",
      "Requirement already satisfied: spacy<2.2,>=2.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (0.20.1)\n",
      "Requirement already satisfied: flask-cors>=3.0.7 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (3.0.7)\n",
      "Requirement already satisfied: gevent>=1.3.6 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from allennlp) (1.4.0)\n",
      "Requirement already satisfied: sentencepiece in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from bpemb>=0.2.9->flair) (0.1.82)\n",
      "Requirement already satisfied: smart-open>=1.2.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from gensim>=3.4.0->flair) (1.7.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (1.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (2.7.5)\n",
      "Requirement already satisfied: cycler>=0.10 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
      "Requirement already satisfied: wrapt<2,>=1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from deprecated>=1.2.4->flair) (1.10.11)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from networkx->hyperopt) (4.3.0)\n",
      "Requirement already satisfied: docutils>=0.10 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (0.14)\n",
      "Requirement already satisfied: rsa<=3.5.0,>=3.1.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (3.4.2)\n",
      "Requirement already satisfied: colorama<=0.3.9,>=0.2.5 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (0.3.9)\n",
      "Collecting s3transfer<0.3.0,>=0.2.0 (from awscli>=1.11.91->allennlp)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/de/5737f602e22073ecbded7a0c590707085e154e32b68d86545dcc31004c02/s3transfer-0.2.0-py2.py3-none-any.whl (69kB)\n",
      "\u001b[K    100% |████████████████████████████████| 71kB 373kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: PyYAML<=3.13,>=3.10 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from awscli>=1.11.91->allennlp) (3.13)\n",
      "Collecting botocore==1.12.151 (from awscli>=1.11.91->allennlp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/57/89/39e9d8a45ff3290c41d47065ec0abc9936925a4bc88bb488e07897d9f38d/botocore-1.12.151-py2.py3-none-any.whl (5.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 5.4MB 5.4MB/s eta 0:00:01    66% |█████████████████████▍          | 3.6MB 3.8MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: cfn-lint in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (0.20.3)\n",
      "Requirement already satisfied: jsondiff==1.1.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (1.1.2)\n",
      "Requirement already satisfied: cryptography>=2.3.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (2.6.1)\n",
      "Requirement already satisfied: boto>=2.36.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (2.49.0)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (2.10.1)\n",
      "Requirement already satisfied: xmltodict in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (0.12.0)\n",
      "Requirement already satisfied: werkzeug in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (0.14.1)\n",
      "Requirement already satisfied: python-jose<4.0.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (3.0.1)\n",
      "Requirement already satisfied: mock in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (3.0.5)\n",
      "Requirement already satisfied: docker>=2.5.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (4.0.1)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (2.7)\n",
      "Requirement already satisfied: aws-xray-sdk!=0.96,>=0.93 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from moto>=1.3.4->allennlp) (2.4.2)\n",
      "Requirement already satisfied: wcwidth in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytest->allennlp) (0.1.7)\n",
      "Requirement already satisfied: pluggy!=0.10,<1.0,>=0.9 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytest->allennlp) (0.11.0)\n",
      "Requirement already satisfied: setuptools in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytest->allennlp) (39.0.1)\n",
      "Requirement already satisfied: atomicwrites>=1.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytest->allennlp) (1.3.0)\n",
      "Requirement already satisfied: more-itertools>=4.0.0; python_version > \"2.7\" in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytest->allennlp) (7.0.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytest->allennlp) (18.2.0)\n",
      "Requirement already satisfied: py>=1.5.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytest->allennlp) (1.8.0)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from boto3->allennlp) (0.9.3)\n",
      "Requirement already satisfied: sphinx>=1.6.5 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from numpydoc>=0.8.0->allennlp) (1.8.2)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests>=2.18->allennlp) (1.24.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests>=2.18->allennlp) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests>=2.18->allennlp) (2018.11.29)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flask>=1.0.2->allennlp) (1.1.0)\n",
      "Requirement already satisfied: click>=5.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from flask>=1.0.2->allennlp) (7.0)\n",
      "Requirement already satisfied: protobuf>=3.2.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorboardX>=1.2->allennlp) (3.6.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (0.2.2)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (2.0.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (0.9.6)\n",
      "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (7.0.4)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (0.0.5)\n",
      "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (2.0.1)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (1.0.2)\n",
      "Requirement already satisfied: jsonschema<3.1.0,>=2.6.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (2.6.0)\n",
      "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from spacy<2.2,>=2.0->allennlp) (0.2.4)\n",
      "Requirement already satisfied: greenlet>=0.4.14; platform_python_implementation == \"CPython\" in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from gevent>=1.3.6->allennlp) (0.4.15)\n",
      "Requirement already satisfied: bz2file in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from smart-open>=1.2.1->gensim>=3.4.0->flair) (0.98)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from rsa<=3.5.0,>=3.1.2->awscli>=1.11.91->allennlp) (0.4.5)\n",
      "Requirement already satisfied: jsonpatch in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from cfn-lint->moto>=1.3.4->allennlp) (1.23)\n",
      "Requirement already satisfied: aws-sam-translator>=1.10.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from cfn-lint->moto>=1.3.4->allennlp) (1.11.0)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from cryptography>=2.3.0->moto>=1.3.4->allennlp) (0.24.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from cryptography>=2.3.0->moto>=1.3.4->allennlp) (1.12.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from Jinja2>=2.10.1->moto>=1.3.4->allennlp) (1.1.0)\n",
      "Requirement already satisfied: ecdsa<1.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from python-jose<4.0.0->moto>=1.3.4->allennlp) (0.13.2)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from docker>=2.5.1->moto>=1.3.4->allennlp) (0.56.0)\n",
      "Requirement already satisfied: jsonpickle in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from aws-xray-sdk!=0.96,>=0.93->moto>=1.3.4->allennlp) (0.9.6)\n",
      "Requirement already satisfied: Pygments>=2.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.3.0)\n",
      "Requirement already satisfied: imagesize in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
      "Requirement already satisfied: snowballstemmer>=1.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.2.1)\n",
      "Requirement already satisfied: babel!=2.0,>=1.3 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (2.6.0)\n",
      "Requirement already satisfied: sphinxcontrib-websupport in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (1.1.0)\n",
      "Requirement already satisfied: alabaster<0.8,>=0.7 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (0.7.12)\n",
      "Requirement already satisfied: packaging in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from sphinx>=1.6.5->numpydoc>=0.8.0->allennlp) (18.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from jsonpatch->cfn-lint->moto>=1.3.4->allennlp) (2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pycparser in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3.0->moto>=1.3.4->allennlp) (2.19)\n",
      "\u001b[31mmoto 1.3.8 has requirement boto3>=1.9.86, but you'll have boto3 1.9.59 which is incompatible.\u001b[0m\n",
      "\u001b[31mboto3 1.9.59 has requirement s3transfer<0.2.0,>=0.1.10, but you'll have s3transfer 0.2.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: botocore, s3transfer\n",
      "  Found existing installation: botocore 1.12.59\n",
      "    Uninstalling botocore-1.12.59:\n",
      "      Successfully uninstalled botocore-1.12.59\n",
      "  Found existing installation: s3transfer 0.1.13\n",
      "    Uninstalling s3transfer-0.1.13:\n",
      "      Successfully uninstalled s3transfer-0.1.13\n",
      "Successfully installed botocore-1.12.151 s3transfer-0.2.0\n",
      "\u001b[33mYou are using pip version 18.1, however version 19.1.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install flair tinydb hyperopt nltk allennlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37038, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HYPERTENSION</th>\n",
       "      <th>CAD</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>texts</th>\n",
       "      <th>doc_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Record date: 2074-12-05\\n\\n \\n \\n \\n \\n \\n \\n ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>228 Caldwell Road\\nColorado City,  NY  43414\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>, simvastatin 10 mg po q.d.,\\namlodipine 5 mg ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>SMOKED UNTIL 8/2/81.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>She had no respiratory symptoms of dyspnea or ...</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HYPERTENSION CAD DIABETES  \\\n",
       "0              []  []       []   \n",
       "1              []  []       []   \n",
       "10             []  []       []   \n",
       "100            []  []       []   \n",
       "1000           []  []       []   \n",
       "\n",
       "                                                  texts  doc_ids  \n",
       "0     Record date: 2074-12-05\\n\\n \\n \\n \\n \\n \\n \\n ...        0  \n",
       "1     228 Caldwell Road\\nColorado City,  NY  43414\\n...        0  \n",
       "10    , simvastatin 10 mg po q.d.,\\namlodipine 5 mg ...        0  \n",
       "100                                SMOKED UNTIL 8/2/81.        1  \n",
       "1000  She had no respiratory symptoms of dyspnea or ...       21  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '../data/all_attributes.json'\n",
    "dataset = pd.read_json(dataset_path)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tinydb\n",
    "results_db = tinydb.TinyDB('../results.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vadim_ml.nlp import char_annotations_as_token_annotations, token_span_to_bio\n",
    "from vadim_ml.memoize import disk_memoize\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "tok = TreebankWordTokenizer()\n",
    "\n",
    "def tokenize_row(row):\n",
    "    text = row['texts']\n",
    "    token_spans = list(tok.span_tokenize(text))\n",
    "    tokens = [text[s:e] for s, e in token_spans]\n",
    "\n",
    "    text_dict = {\n",
    "        'text': tokens,\n",
    "    }\n",
    "\n",
    "    for pat in ('HYPERTENSION', 'CAD', 'DIABETES'):\n",
    "        spans = char_annotations_as_token_annotations(token_spans, row[pat])\n",
    "        text_dict[pat] = token_span_to_bio(tokens, spans)\n",
    "\n",
    "    return text_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data_fetcher import NLPTaskDataFetcher\n",
    "import os\n",
    "\n",
    "def produce_column_corpus(sentence_dicts, folds, column_fields, path): \n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    files = {}\n",
    "    \n",
    "    for text_dict, fold in zip(sentence_dicts, folds):\n",
    "        try:\n",
    "            file = files[fold]\n",
    "        except KeyError:\n",
    "            files[fold] = open(os.path.join(path, fold + '.txt'), 'w')\n",
    "        \n",
    "        for line in zip(*(text_dict[c] for c in column_fields)):\n",
    "            files[fold].write('\\t'.join(line) + '\\n')\n",
    "            \n",
    "        files[fold].write('\\n')\n",
    "        \n",
    "    for file in files.values():\n",
    "        file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def train_dev_test_distr():\n",
    "    x = random.random()\n",
    "    if x < 0.2:\n",
    "        return 'test'\n",
    "    elif x < 0.4:\n",
    "        return 'dev'\n",
    "    else:\n",
    "        return 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "\n",
    "corpus_path = '../data/columncorpus'\n",
    "columns = {0: 'text', 1: 'HYPERTENSION', 2: 'CAD', 3: 'DIABETES'}\n",
    "\n",
    "def column_corpus():\n",
    "    try:\n",
    "        return NLPTaskDataFetcher.load_column_corpus(corpus_path, columns, \n",
    "                                                     train_file='train.txt',\n",
    "                                                     test_file='test.txt',\n",
    "                                                     dev_file='dev.txt')\n",
    "    except FileNotFoundError:\n",
    "        irows = dataset.iterrows()\n",
    "        texts = (tokenize_row(row) for idx, row in tqdm_notebook(irows))\n",
    "        folds = (train_dev_test_distr() for i in iter(int, 1))\n",
    "        produce_column_corpus(texts, folds, columns.values(), corpus_path)\n",
    "        return NLPTaskDataFetcher.load_column_corpus(corpus_path, columns, \n",
    "                                                     train_file='train.txt',\n",
    "                                                     test_file='test.txt',\n",
    "                                                     dev_file='dev.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-31 02:09:58,478 Reading data from ../data/columncorpus\n",
      "2019-05-31 02:09:58,479 Train: ../data/columncorpus/train.txt\n",
      "2019-05-31 02:09:58,480 Dev: ../data/columncorpus/dev.txt\n",
      "2019-05-31 02:09:58,481 Test: ../data/columncorpus/test.txt\n"
     ]
    }
   ],
   "source": [
    "corpus = column_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flair sequence tagger\n",
    "\n",
    "Flair embeddings trained on PubMed abstracts with BiLSTM-CRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dictionary is the same fro all 3 pathology\n",
    "tag_dictionary = corpus.make_tag_dictionary('HYPERTENSION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 09:33:05,011 https://s3.eu-central-1.amazonaws.com/alan-nlp/resources/embeddings-v0.4.1/pubmed-2015-bw-lm.pt not found in cache, downloading to /tmp/tmp5d92gn7x\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111081366/111081366 [00:11<00:00, 10068748.57B/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 09:33:16,354 copying /tmp/tmp5d92gn7x to cache at /root/.flair/embeddings/pubmed-2015-bw-lm.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 09:33:16,982 removing temp file /tmp/tmp5d92gn7x\n"
     ]
    }
   ],
   "source": [
    "embeddings = StackedEmbeddings([WordEmbeddings('glove'), \n",
    "                                FlairEmbeddings('pubmed-forward'), \n",
    "                                FlairEmbeddings('pubmed-backward'),\n",
    "                               ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.training_utils import EvaluationMetric\n",
    "\n",
    "def train_tagger(pathology, embeddings, folder):\n",
    "    tagger = SequenceTagger(hidden_size=256,\n",
    "                           embeddings=embeddings,\n",
    "                           tag_dictionary=tag_dictionary,\n",
    "                           tag_type=pathology,\n",
    "                           use_crf=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    trainer = ModelTrainer(tagger, corpus)\n",
    "    trainer.train(f'../models/{folder}',\n",
    "                  EvaluationMetric.MICRO_F1_SCORE,\n",
    "                  learning_rate=0.1,\n",
    "                  mini_batch_size=32,\n",
    "                  max_epochs=150,\n",
    "                  checkpoint=True)\n",
    "    \n",
    "    return tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYPERTENSION\n",
      "2019-05-13 09:56:20,619 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 09:56:20,620 Evaluation method: MICRO_F1_SCORE\n",
      "2019-05-13 09:56:20,622 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 09:56:21,381 epoch 1 - iter 0/693 - loss 19.90345383\n",
      "2019-05-13 09:56:41,181 epoch 1 - iter 69/693 - loss 0.79330848\n",
      "2019-05-13 09:57:02,946 epoch 1 - iter 138/693 - loss 0.63059303\n",
      "2019-05-13 09:57:25,740 epoch 1 - iter 207/693 - loss 0.52976911\n",
      "2019-05-13 09:57:48,526 epoch 1 - iter 276/693 - loss 0.47508759\n",
      "2019-05-13 09:58:08,615 epoch 1 - iter 345/693 - loss 0.43311270\n",
      "2019-05-13 09:58:32,522 epoch 1 - iter 414/693 - loss 0.41281813\n",
      "2019-05-13 09:58:55,792 epoch 1 - iter 483/693 - loss 0.38964588\n",
      "2019-05-13 09:59:20,066 epoch 1 - iter 552/693 - loss 0.37273970\n",
      "2019-05-13 09:59:41,577 epoch 1 - iter 621/693 - loss 0.35172129\n",
      "2019-05-13 10:00:04,208 epoch 1 - iter 690/693 - loss 0.33757529\n",
      "2019-05-13 10:00:05,113 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:00:05,115 EPOCH 1 done: loss 0.3369 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 10:01:05,134 DEV  : loss 0.23622246 - f-score 0.2865 - acc 0.1672\n",
      "2019-05-13 10:02:08,584 TEST : loss 0.19786546 - f-score 0.3147 - acc 0.1868\n",
      "2019-05-13 10:02:21,581 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:02:21,780 epoch 2 - iter 0/693 - loss 0.03469601\n",
      "2019-05-13 10:02:42,919 epoch 2 - iter 69/693 - loss 0.23292817\n",
      "2019-05-13 10:03:05,187 epoch 2 - iter 138/693 - loss 0.19883475\n",
      "2019-05-13 10:03:29,807 epoch 2 - iter 207/693 - loss 0.21140277\n",
      "2019-05-13 10:03:50,519 epoch 2 - iter 276/693 - loss 0.20709220\n",
      "2019-05-13 10:04:14,733 epoch 2 - iter 345/693 - loss 0.20897897\n",
      "2019-05-13 10:04:38,959 epoch 2 - iter 414/693 - loss 0.21059701\n",
      "2019-05-13 10:05:01,211 epoch 2 - iter 483/693 - loss 0.20437461\n",
      "2019-05-13 10:05:22,693 epoch 2 - iter 552/693 - loss 0.20069646\n",
      "2019-05-13 10:05:44,916 epoch 2 - iter 621/693 - loss 0.19575165\n",
      "2019-05-13 10:06:06,390 epoch 2 - iter 690/693 - loss 0.19481403\n",
      "2019-05-13 10:06:06,861 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:06:06,863 EPOCH 2 done: loss 0.1944 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 10:07:04,052 DEV  : loss 0.13499506 - f-score 0.4797 - acc 0.3155\n",
      "2019-05-13 10:08:06,546 TEST : loss 0.12104956 - f-score 0.5074 - acc 0.3400\n",
      "2019-05-13 10:08:19,653 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:08:19,982 epoch 3 - iter 0/693 - loss 0.05729079\n",
      "2019-05-13 10:08:42,572 epoch 3 - iter 69/693 - loss 0.15364726\n",
      "2019-05-13 10:09:04,415 epoch 3 - iter 138/693 - loss 0.16620047\n",
      "2019-05-13 10:09:28,111 epoch 3 - iter 207/693 - loss 0.17248165\n",
      "2019-05-13 10:09:51,455 epoch 3 - iter 276/693 - loss 0.17269545\n",
      "2019-05-13 10:10:12,568 epoch 3 - iter 345/693 - loss 0.17636735\n",
      "2019-05-13 10:10:35,741 epoch 3 - iter 414/693 - loss 0.17207775\n",
      "2019-05-13 10:10:55,634 epoch 3 - iter 483/693 - loss 0.16698725\n",
      "2019-05-13 10:11:17,849 epoch 3 - iter 552/693 - loss 0.16595460\n",
      "2019-05-13 10:11:42,326 epoch 3 - iter 621/693 - loss 0.16632480\n",
      "2019-05-13 10:12:02,805 epoch 3 - iter 690/693 - loss 0.16670797\n",
      "2019-05-13 10:12:03,340 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:12:03,341 EPOCH 3 done: loss 0.1664 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 10:13:00,844 DEV  : loss 0.11639056 - f-score 0.4905 - acc 0.3249\n",
      "2019-05-13 10:14:02,018 TEST : loss 0.10148665 - f-score 0.5112 - acc 0.3434\n",
      "2019-05-13 10:14:15,095 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:14:15,414 epoch 4 - iter 0/693 - loss 0.00296789\n",
      "2019-05-13 10:14:37,492 epoch 4 - iter 69/693 - loss 0.16147610\n",
      "2019-05-13 10:15:00,902 epoch 4 - iter 138/693 - loss 0.17112028\n",
      "2019-05-13 10:15:24,719 epoch 4 - iter 207/693 - loss 0.17226999\n",
      "2019-05-13 10:15:44,950 epoch 4 - iter 276/693 - loss 0.16713935\n",
      "2019-05-13 10:16:06,877 epoch 4 - iter 345/693 - loss 0.16271624\n",
      "2019-05-13 10:16:32,191 epoch 4 - iter 414/693 - loss 0.16253682\n",
      "2019-05-13 10:16:56,069 epoch 4 - iter 483/693 - loss 0.16847184\n",
      "2019-05-13 10:17:18,738 epoch 4 - iter 552/693 - loss 0.16490433\n",
      "2019-05-13 10:17:36,401 epoch 4 - iter 621/693 - loss 0.15762742\n",
      "2019-05-13 10:17:58,046 epoch 4 - iter 690/693 - loss 0.15623607\n",
      "2019-05-13 10:17:58,408 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:17:58,409 EPOCH 4 done: loss 0.1565 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 10:18:57,823 DEV  : loss 0.10348213 - f-score 0.6218 - acc 0.4511\n",
      "2019-05-13 10:20:00,960 TEST : loss 0.09899005 - f-score 0.5820 - acc 0.4104\n",
      "2019-05-13 10:20:13,936 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:20:14,187 epoch 5 - iter 0/693 - loss 0.04148412\n",
      "2019-05-13 10:20:33,770 epoch 5 - iter 69/693 - loss 0.15598976\n",
      "2019-05-13 10:20:56,494 epoch 5 - iter 138/693 - loss 0.14441390\n",
      "2019-05-13 10:21:19,401 epoch 5 - iter 207/693 - loss 0.14309008\n",
      "2019-05-13 10:21:42,055 epoch 5 - iter 276/693 - loss 0.13896019\n",
      "2019-05-13 10:22:02,306 epoch 5 - iter 345/693 - loss 0.13321277\n",
      "2019-05-13 10:22:27,394 epoch 5 - iter 414/693 - loss 0.14179151\n",
      "2019-05-13 10:22:49,875 epoch 5 - iter 483/693 - loss 0.14613852\n",
      "2019-05-13 10:23:13,236 epoch 5 - iter 552/693 - loss 0.14321977\n",
      "2019-05-13 10:23:35,831 epoch 5 - iter 621/693 - loss 0.14979582\n",
      "2019-05-13 10:23:56,546 epoch 5 - iter 690/693 - loss 0.14677839\n",
      "2019-05-13 10:23:57,345 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:23:57,347 EPOCH 5 done: loss 0.1468 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 10:24:54,845 DEV  : loss 0.14402619 - f-score 0.4824 - acc 0.3178\n",
      "2019-05-13 10:25:56,026 TEST : loss 0.12253389 - f-score 0.4930 - acc 0.3271\n",
      "2019-05-13 10:26:09,072 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:26:09,354 epoch 6 - iter 0/693 - loss 0.29551187\n",
      "2019-05-13 10:26:31,079 epoch 6 - iter 69/693 - loss 0.14087700\n",
      "2019-05-13 10:26:53,300 epoch 6 - iter 138/693 - loss 0.13023636\n",
      "2019-05-13 10:27:13,755 epoch 6 - iter 207/693 - loss 0.13937213\n",
      "2019-05-13 10:27:37,467 epoch 6 - iter 276/693 - loss 0.14674260\n",
      "2019-05-13 10:27:59,147 epoch 6 - iter 345/693 - loss 0.14220178\n",
      "2019-05-13 10:28:24,147 epoch 6 - iter 414/693 - loss 0.14271747\n",
      "2019-05-13 10:28:43,787 epoch 6 - iter 483/693 - loss 0.13800867\n",
      "2019-05-13 10:29:06,168 epoch 6 - iter 552/693 - loss 0.13855420\n",
      "2019-05-13 10:29:28,652 epoch 6 - iter 621/693 - loss 0.13845086\n",
      "2019-05-13 10:29:47,304 epoch 6 - iter 690/693 - loss 0.14405491\n",
      "2019-05-13 10:29:48,007 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:29:48,008 EPOCH 6 done: loss 0.1444 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 10:30:46,546 DEV  : loss 0.10435136 - f-score 0.4289 - acc 0.2730\n",
      "2019-05-13 10:31:47,935 TEST : loss 0.09005856 - f-score 0.4211 - acc 0.2667\n",
      "2019-05-13 10:32:01,053 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:32:01,299 epoch 7 - iter 0/693 - loss 0.00837207\n",
      "2019-05-13 10:32:23,835 epoch 7 - iter 69/693 - loss 0.12792333\n",
      "2019-05-13 10:32:48,226 epoch 7 - iter 138/693 - loss 0.15253670\n",
      "2019-05-13 10:33:12,035 epoch 7 - iter 207/693 - loss 0.13997009\n",
      "2019-05-13 10:33:35,749 epoch 7 - iter 276/693 - loss 0.14328173\n",
      "2019-05-13 10:33:59,932 epoch 7 - iter 345/693 - loss 0.14253134\n",
      "2019-05-13 10:34:23,320 epoch 7 - iter 414/693 - loss 0.14132107\n",
      "2019-05-13 10:34:46,665 epoch 7 - iter 483/693 - loss 0.14277427\n",
      "2019-05-13 10:35:06,890 epoch 7 - iter 552/693 - loss 0.13573393\n",
      "2019-05-13 10:35:29,716 epoch 7 - iter 621/693 - loss 0.13453465\n",
      "2019-05-13 10:35:50,837 epoch 7 - iter 690/693 - loss 0.13557346\n",
      "2019-05-13 10:35:51,381 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 10:35:51,383 EPOCH 7 done: loss 0.1357 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 10:36:50,135 DEV  : loss 0.11631372 - f-score 0.3905 - acc 0.2426\n",
      "2019-05-13 10:37:52,571 TEST : loss 0.09813494 - f-score 0.4228 - acc 0.2681\n",
      "2019-05-13 10:38:05,766 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:38:06,066 epoch 8 - iter 0/693 - loss 0.04144216\n",
      "2019-05-13 10:38:28,059 epoch 8 - iter 69/693 - loss 0.10165724\n",
      "2019-05-13 10:38:54,116 epoch 8 - iter 138/693 - loss 0.11263817\n",
      "2019-05-13 10:39:20,243 epoch 8 - iter 207/693 - loss 0.11782995\n",
      "2019-05-13 10:39:44,428 epoch 8 - iter 276/693 - loss 0.12288016\n",
      "2019-05-13 10:40:06,782 epoch 8 - iter 345/693 - loss 0.13138471\n",
      "2019-05-13 10:40:31,997 epoch 8 - iter 414/693 - loss 0.13184896\n",
      "2019-05-13 10:40:53,367 epoch 8 - iter 483/693 - loss 0.13542160\n",
      "2019-05-13 10:41:17,386 epoch 8 - iter 552/693 - loss 0.13681434\n",
      "2019-05-13 10:41:38,869 epoch 8 - iter 621/693 - loss 0.13660337\n",
      "2019-05-13 10:42:00,525 epoch 8 - iter 690/693 - loss 0.13808918\n",
      "2019-05-13 10:42:00,883 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:42:00,884 EPOCH 8 done: loss 0.1387 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 10:42:57,714 DEV  : loss 0.10311933 - f-score 0.4447 - acc 0.2859\n",
      "2019-05-13 10:43:57,975 TEST : loss 0.09247357 - f-score 0.4265 - acc 0.2710\n",
      "2019-05-13 10:44:04,282 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:44:04,532 epoch 9 - iter 0/693 - loss 0.00333247\n",
      "2019-05-13 10:44:28,623 epoch 9 - iter 69/693 - loss 0.13593774\n",
      "2019-05-13 10:44:51,116 epoch 9 - iter 138/693 - loss 0.13827172\n",
      "2019-05-13 10:45:13,825 epoch 9 - iter 207/693 - loss 0.14079309\n",
      "2019-05-13 10:45:37,381 epoch 9 - iter 276/693 - loss 0.14581978\n",
      "2019-05-13 10:46:04,065 epoch 9 - iter 345/693 - loss 0.14620533\n",
      "2019-05-13 10:46:27,034 epoch 9 - iter 414/693 - loss 0.14028394\n",
      "2019-05-13 10:46:49,106 epoch 9 - iter 483/693 - loss 0.13979514\n",
      "2019-05-13 10:47:12,404 epoch 9 - iter 552/693 - loss 0.13721051\n",
      "2019-05-13 10:47:36,475 epoch 9 - iter 621/693 - loss 0.13025329\n",
      "2019-05-13 10:47:56,007 epoch 9 - iter 690/693 - loss 0.12985741\n",
      "2019-05-13 10:47:56,512 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:47:56,514 EPOCH 9 done: loss 0.1307 - lr 0.1000 - bad epochs 1\n",
      "2019-05-13 10:48:53,915 DEV  : loss 0.11878395 - f-score 0.5767 - acc 0.4052\n",
      "2019-05-13 10:49:57,733 TEST : loss 0.11482316 - f-score 0.5453 - acc 0.3748\n",
      "2019-05-13 10:50:10,567 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:50:11,520 epoch 10 - iter 0/693 - loss 0.40039390\n",
      "2019-05-13 10:50:35,205 epoch 10 - iter 69/693 - loss 0.14163712\n",
      "2019-05-13 10:50:57,072 epoch 10 - iter 138/693 - loss 0.12884563\n",
      "2019-05-13 10:51:19,849 epoch 10 - iter 207/693 - loss 0.14114518\n",
      "2019-05-13 10:51:39,434 epoch 10 - iter 276/693 - loss 0.12589591\n",
      "2019-05-13 10:52:02,914 epoch 10 - iter 345/693 - loss 0.11785032\n",
      "2019-05-13 10:52:24,262 epoch 10 - iter 414/693 - loss 0.11932894\n",
      "2019-05-13 10:52:46,853 epoch 10 - iter 483/693 - loss 0.12410993\n",
      "2019-05-13 10:53:11,550 epoch 10 - iter 552/693 - loss 0.12900047\n",
      "2019-05-13 10:53:36,494 epoch 10 - iter 621/693 - loss 0.13015221\n",
      "2019-05-13 10:53:57,343 epoch 10 - iter 690/693 - loss 0.12902803\n",
      "2019-05-13 10:53:57,824 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:53:57,825 EPOCH 10 done: loss 0.1290 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 10:54:55,190 DEV  : loss 0.11279443 - f-score 0.4931 - acc 0.3272\n",
      "2019-05-13 10:55:56,287 TEST : loss 0.09679566 - f-score 0.5162 - acc 0.3479\n",
      "2019-05-13 10:56:09,092 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:56:09,284 epoch 11 - iter 0/693 - loss 0.00941461\n",
      "2019-05-13 10:56:31,386 epoch 11 - iter 69/693 - loss 0.12792017\n",
      "2019-05-13 10:56:54,029 epoch 11 - iter 138/693 - loss 0.12981090\n",
      "2019-05-13 10:57:16,503 epoch 11 - iter 207/693 - loss 0.12535818\n",
      "2019-05-13 10:57:41,914 epoch 11 - iter 276/693 - loss 0.12191073\n",
      "2019-05-13 10:58:04,851 epoch 11 - iter 345/693 - loss 0.12025976\n",
      "2019-05-13 10:58:27,336 epoch 11 - iter 414/693 - loss 0.11869312\n",
      "2019-05-13 10:58:49,237 epoch 11 - iter 483/693 - loss 0.11556158\n",
      "2019-05-13 10:59:13,773 epoch 11 - iter 552/693 - loss 0.12022419\n",
      "2019-05-13 10:59:37,127 epoch 11 - iter 621/693 - loss 0.12181309\n",
      "2019-05-13 10:59:57,460 epoch 11 - iter 690/693 - loss 0.12109627\n",
      "2019-05-13 10:59:58,187 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 10:59:58,189 EPOCH 11 done: loss 0.1208 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 11:00:58,145 DEV  : loss 0.18095240 - f-score 0.3979 - acc 0.2484\n",
      "2019-05-13 11:02:01,714 TEST : loss 0.15493932 - f-score 0.4217 - acc 0.2672\n",
      "2019-05-13 11:02:14,944 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:02:15,401 epoch 12 - iter 0/693 - loss 0.00797540\n",
      "2019-05-13 11:02:37,511 epoch 12 - iter 69/693 - loss 0.14153139\n",
      "2019-05-13 11:02:59,265 epoch 12 - iter 138/693 - loss 0.13732897\n",
      "2019-05-13 11:03:22,246 epoch 12 - iter 207/693 - loss 0.14223261\n",
      "2019-05-13 11:03:48,219 epoch 12 - iter 276/693 - loss 0.13695487\n",
      "2019-05-13 11:04:10,440 epoch 12 - iter 345/693 - loss 0.13300860\n",
      "2019-05-13 11:04:37,097 epoch 12 - iter 414/693 - loss 0.13018169\n",
      "2019-05-13 11:04:57,081 epoch 12 - iter 483/693 - loss 0.12628110\n",
      "2019-05-13 11:05:16,737 epoch 12 - iter 552/693 - loss 0.13073890\n",
      "2019-05-13 11:05:35,247 epoch 12 - iter 621/693 - loss 0.12816220\n",
      "2019-05-13 11:05:57,073 epoch 12 - iter 690/693 - loss 0.12480407\n",
      "2019-05-13 11:05:57,636 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:05:57,638 EPOCH 12 done: loss 0.1246 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 11:06:57,165 DEV  : loss 0.15207307 - f-score 0.3646 - acc 0.2230\n",
      "2019-05-13 11:08:00,453 TEST : loss 0.11977611 - f-score 0.4048 - acc 0.2538\n",
      "2019-05-13 11:08:06,818 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:08:07,021 epoch 13 - iter 0/693 - loss 0.00066340\n",
      "2019-05-13 11:08:29,401 epoch 13 - iter 69/693 - loss 0.12211081\n",
      "2019-05-13 11:08:51,334 epoch 13 - iter 138/693 - loss 0.12433709\n",
      "2019-05-13 11:09:11,306 epoch 13 - iter 207/693 - loss 0.12579154\n",
      "2019-05-13 11:09:33,579 epoch 13 - iter 276/693 - loss 0.12788262\n",
      "2019-05-13 11:09:58,180 epoch 13 - iter 345/693 - loss 0.12973140\n",
      "2019-05-13 11:10:20,755 epoch 13 - iter 414/693 - loss 0.12534257\n",
      "2019-05-13 11:10:40,921 epoch 13 - iter 483/693 - loss 0.12614683\n",
      "2019-05-13 11:11:03,468 epoch 13 - iter 552/693 - loss 0.12500885\n",
      "2019-05-13 11:11:24,495 epoch 13 - iter 621/693 - loss 0.12595644\n",
      "2019-05-13 11:11:48,789 epoch 13 - iter 690/693 - loss 0.12690382\n",
      "2019-05-13 11:11:49,535 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:11:49,537 EPOCH 13 done: loss 0.1269 - lr 0.1000 - bad epochs 1\n",
      "2019-05-13 11:12:46,554 DEV  : loss 0.13732129 - f-score 0.4399 - acc 0.2820\n",
      "2019-05-13 11:13:46,999 TEST : loss 0.11443777 - f-score 0.4913 - acc 0.3257\n",
      "2019-05-13 11:13:53,277 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:13:53,586 epoch 14 - iter 0/693 - loss 0.21007559\n",
      "2019-05-13 11:14:17,648 epoch 14 - iter 69/693 - loss 0.08765422\n",
      "2019-05-13 11:14:42,040 epoch 14 - iter 138/693 - loss 0.10686262\n",
      "2019-05-13 11:15:04,278 epoch 14 - iter 207/693 - loss 0.11727516\n",
      "2019-05-13 11:15:26,328 epoch 14 - iter 276/693 - loss 0.11250970\n",
      "2019-05-13 11:15:45,995 epoch 14 - iter 345/693 - loss 0.10824078\n",
      "2019-05-13 11:16:08,843 epoch 14 - iter 414/693 - loss 0.11111659\n",
      "2019-05-13 11:16:26,559 epoch 14 - iter 483/693 - loss 0.11192179\n",
      "2019-05-13 11:16:48,013 epoch 14 - iter 552/693 - loss 0.11363301\n",
      "2019-05-13 11:17:07,373 epoch 14 - iter 621/693 - loss 0.11451293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 11:17:26,449 epoch 14 - iter 690/693 - loss 0.11696168\n",
      "2019-05-13 11:17:27,011 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:17:27,012 EPOCH 14 done: loss 0.1168 - lr 0.1000 - bad epochs 2\n",
      "2019-05-13 11:18:24,274 DEV  : loss 0.10381896 - f-score 0.5406 - acc 0.3705\n",
      "2019-05-13 11:19:25,340 TEST : loss 0.09096314 - f-score 0.5580 - acc 0.3869\n",
      "2019-05-13 11:19:38,507 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:19:39,162 epoch 15 - iter 0/693 - loss 0.06764615\n",
      "2019-05-13 11:20:02,565 epoch 15 - iter 69/693 - loss 0.15816344\n",
      "2019-05-13 11:20:22,187 epoch 15 - iter 138/693 - loss 0.13901940\n",
      "2019-05-13 11:20:43,253 epoch 15 - iter 207/693 - loss 0.12334205\n",
      "2019-05-13 11:21:03,930 epoch 15 - iter 276/693 - loss 0.11509385\n",
      "2019-05-13 11:21:23,057 epoch 15 - iter 345/693 - loss 0.11788456\n",
      "2019-05-13 11:21:43,757 epoch 15 - iter 414/693 - loss 0.12027038\n",
      "2019-05-13 11:22:02,483 epoch 15 - iter 483/693 - loss 0.11755821\n",
      "2019-05-13 11:22:19,586 epoch 15 - iter 552/693 - loss 0.11881362\n",
      "2019-05-13 11:22:44,447 epoch 15 - iter 621/693 - loss 0.11528518\n",
      "2019-05-13 11:23:04,588 epoch 15 - iter 690/693 - loss 0.11934652\n",
      "2019-05-13 11:23:05,273 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:23:05,276 EPOCH 15 done: loss 0.1203 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 11:24:02,836 DEV  : loss 0.10007384 - f-score 0.5179 - acc 0.3495\n",
      "2019-05-13 11:25:03,918 TEST : loss 0.08703196 - f-score 0.4794 - acc 0.3153\n",
      "2019-05-13 11:25:10,287 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:25:10,478 epoch 16 - iter 0/693 - loss 0.00963980\n",
      "2019-05-13 11:25:32,011 epoch 16 - iter 69/693 - loss 0.09373063\n",
      "2019-05-13 11:25:54,076 epoch 16 - iter 138/693 - loss 0.11662279\n",
      "2019-05-13 11:26:19,684 epoch 16 - iter 207/693 - loss 0.12693801\n",
      "2019-05-13 11:26:42,075 epoch 16 - iter 276/693 - loss 0.12134467\n",
      "2019-05-13 11:27:06,770 epoch 16 - iter 345/693 - loss 0.12306808\n",
      "2019-05-13 11:27:28,236 epoch 16 - iter 414/693 - loss 0.11583306\n",
      "2019-05-13 11:27:48,803 epoch 16 - iter 483/693 - loss 0.11801460\n",
      "2019-05-13 11:28:11,056 epoch 16 - iter 552/693 - loss 0.12012888\n",
      "2019-05-13 11:28:32,631 epoch 16 - iter 621/693 - loss 0.11906927\n",
      "2019-05-13 11:28:54,438 epoch 16 - iter 690/693 - loss 0.11904079\n",
      "2019-05-13 11:28:54,866 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:28:54,867 EPOCH 16 done: loss 0.1191 - lr 0.1000 - bad epochs 1\n",
      "2019-05-13 11:29:52,173 DEV  : loss 0.10942995 - f-score 0.5345 - acc 0.3647\n",
      "2019-05-13 11:30:53,215 TEST : loss 0.09267557 - f-score 0.5783 - acc 0.4068\n",
      "2019-05-13 11:30:59,517 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:30:59,766 epoch 17 - iter 0/693 - loss 0.06435156\n",
      "2019-05-13 11:31:26,338 epoch 17 - iter 69/693 - loss 0.11732051\n",
      "2019-05-13 11:31:46,847 epoch 17 - iter 138/693 - loss 0.10345728\n",
      "2019-05-13 11:32:08,895 epoch 17 - iter 207/693 - loss 0.11193888\n",
      "2019-05-13 11:32:33,692 epoch 17 - iter 276/693 - loss 0.11009859\n",
      "2019-05-13 11:32:56,462 epoch 17 - iter 345/693 - loss 0.10731541\n",
      "2019-05-13 11:33:18,273 epoch 17 - iter 414/693 - loss 0.10710407\n",
      "2019-05-13 11:33:42,694 epoch 17 - iter 483/693 - loss 0.11089170\n",
      "2019-05-13 11:34:01,408 epoch 17 - iter 552/693 - loss 0.11091907\n",
      "2019-05-13 11:34:20,677 epoch 17 - iter 621/693 - loss 0.10985726\n",
      "2019-05-13 11:34:40,021 epoch 17 - iter 690/693 - loss 0.11028085\n",
      "2019-05-13 11:34:40,411 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:34:40,413 EPOCH 17 done: loss 0.1102 - lr 0.1000 - bad epochs 2\n",
      "2019-05-13 11:35:40,928 DEV  : loss 0.11633849 - f-score 0.4624 - acc 0.3008\n",
      "2019-05-13 11:36:43,375 TEST : loss 0.09707433 - f-score 0.4674 - acc 0.3049\n",
      "2019-05-13 11:36:56,171 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:36:56,621 epoch 18 - iter 0/693 - loss 0.32110319\n",
      "2019-05-13 11:37:17,447 epoch 18 - iter 69/693 - loss 0.09296769\n",
      "2019-05-13 11:37:41,643 epoch 18 - iter 138/693 - loss 0.10341691\n",
      "2019-05-13 11:38:04,346 epoch 18 - iter 207/693 - loss 0.11422736\n",
      "2019-05-13 11:38:27,136 epoch 18 - iter 276/693 - loss 0.11210973\n",
      "2019-05-13 11:38:48,745 epoch 18 - iter 345/693 - loss 0.10710420\n",
      "2019-05-13 11:39:09,340 epoch 18 - iter 414/693 - loss 0.11169822\n",
      "2019-05-13 11:39:33,119 epoch 18 - iter 483/693 - loss 0.11171345\n",
      "2019-05-13 11:39:53,978 epoch 18 - iter 552/693 - loss 0.11459699\n",
      "2019-05-13 11:40:16,955 epoch 18 - iter 621/693 - loss 0.11215866\n",
      "2019-05-13 11:40:38,865 epoch 18 - iter 690/693 - loss 0.11665263\n",
      "2019-05-13 11:40:39,277 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:40:39,279 EPOCH 18 done: loss 0.1166 - lr 0.1000 - bad epochs 0\n",
      "2019-05-13 11:41:39,007 DEV  : loss 0.11885558 - f-score 0.5157 - acc 0.3474\n",
      "2019-05-13 11:42:42,598 TEST : loss 0.09691580 - f-score 0.5191 - acc 0.3505\n",
      "2019-05-13 11:42:48,859 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:42:49,406 epoch 19 - iter 0/693 - loss 0.01336899\n",
      "2019-05-13 11:43:09,129 epoch 19 - iter 69/693 - loss 0.12662954\n",
      "2019-05-13 11:43:27,277 epoch 19 - iter 138/693 - loss 0.12136555\n",
      "2019-05-13 11:43:50,053 epoch 19 - iter 207/693 - loss 0.10864961\n",
      "2019-05-13 11:44:11,833 epoch 19 - iter 276/693 - loss 0.11924412\n",
      "2019-05-13 11:44:37,137 epoch 19 - iter 345/693 - loss 0.11562706\n",
      "2019-05-13 11:44:59,914 epoch 19 - iter 414/693 - loss 0.12034018\n",
      "2019-05-13 11:45:17,607 epoch 19 - iter 483/693 - loss 0.11830053\n",
      "2019-05-13 11:45:40,157 epoch 19 - iter 552/693 - loss 0.11886557\n",
      "2019-05-13 11:46:00,970 epoch 19 - iter 621/693 - loss 0.12038536\n",
      "2019-05-13 11:46:22,635 epoch 19 - iter 690/693 - loss 0.11720283\n",
      "2019-05-13 11:46:23,178 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:46:23,180 EPOCH 19 done: loss 0.1172 - lr 0.1000 - bad epochs 1\n",
      "2019-05-13 11:47:22,093 DEV  : loss 0.11378147 - f-score 0.5991 - acc 0.4276\n",
      "2019-05-13 11:48:23,504 TEST : loss 0.09677147 - f-score 0.6027 - acc 0.4314\n",
      "2019-05-13 11:48:29,897 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:48:30,117 epoch 20 - iter 0/693 - loss 0.00161740\n",
      "2019-05-13 11:48:52,571 epoch 20 - iter 69/693 - loss 0.13441641\n",
      "2019-05-13 11:49:16,851 epoch 20 - iter 138/693 - loss 0.12468599\n",
      "2019-05-13 11:49:41,984 epoch 20 - iter 207/693 - loss 0.11607270\n",
      "2019-05-13 11:50:04,463 epoch 20 - iter 276/693 - loss 0.11766982\n",
      "2019-05-13 11:50:26,785 epoch 20 - iter 345/693 - loss 0.11679266\n",
      "2019-05-13 11:50:47,533 epoch 20 - iter 414/693 - loss 0.11423152\n",
      "2019-05-13 11:51:09,378 epoch 20 - iter 483/693 - loss 0.11491396\n",
      "2019-05-13 11:51:31,539 epoch 20 - iter 552/693 - loss 0.11360799\n",
      "2019-05-13 11:51:52,130 epoch 20 - iter 621/693 - loss 0.11511845\n",
      "2019-05-13 11:52:13,937 epoch 20 - iter 690/693 - loss 0.11607308\n",
      "2019-05-13 11:52:14,575 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:52:14,578 EPOCH 20 done: loss 0.1164 - lr 0.1000 - bad epochs 2\n",
      "2019-05-13 11:53:14,097 DEV  : loss 0.10553144 - f-score 0.5462 - acc 0.3757\n",
      "2019-05-13 11:54:17,394 TEST : loss 0.09246250 - f-score 0.5708 - acc 0.3994\n",
      "2019-05-13 11:54:23,742 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:54:23,973 epoch 21 - iter 0/693 - loss 0.00047314\n",
      "2019-05-13 11:54:46,988 epoch 21 - iter 69/693 - loss 0.12120788\n",
      "2019-05-13 11:55:12,200 epoch 21 - iter 138/693 - loss 0.11681397\n",
      "2019-05-13 11:55:35,413 epoch 21 - iter 207/693 - loss 0.11317471\n",
      "2019-05-13 11:55:59,225 epoch 21 - iter 276/693 - loss 0.10877165\n",
      "2019-05-13 11:56:18,658 epoch 21 - iter 345/693 - loss 0.10877766\n",
      "2019-05-13 11:56:39,120 epoch 21 - iter 414/693 - loss 0.10551614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-13 11:57:00,615 epoch 21 - iter 483/693 - loss 0.10715379\n",
      "2019-05-13 11:57:25,170 epoch 21 - iter 552/693 - loss 0.11048361\n",
      "2019-05-13 11:57:49,367 epoch 21 - iter 621/693 - loss 0.11282889\n",
      "2019-05-13 11:58:09,877 epoch 21 - iter 690/693 - loss 0.11466386\n",
      "2019-05-13 11:58:10,546 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 11:58:10,547 EPOCH 21 done: loss 0.1144 - lr 0.1000 - bad epochs 3\n",
      "2019-05-13 11:59:08,465 DEV  : loss 0.12368022 - f-score 0.5330 - acc 0.3634\n",
      "2019-05-13 12:00:09,716 TEST : loss 0.10091684 - f-score 0.5683 - acc 0.3969\n",
      "Epoch    20: reducing learning rate of group 0 to 5.0000e-02.\n",
      "2019-05-13 12:00:16,014 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 12:00:16,495 epoch 22 - iter 0/693 - loss 0.00104624\n",
      "2019-05-13 12:00:39,381 epoch 22 - iter 69/693 - loss 0.08153063\n",
      "2019-05-13 12:01:06,673 epoch 22 - iter 138/693 - loss 0.08378166\n",
      "2019-05-13 12:01:26,894 epoch 22 - iter 207/693 - loss 0.08181604\n",
      "2019-05-13 12:01:46,648 epoch 22 - iter 276/693 - loss 0.08894394\n",
      "2019-05-13 12:02:05,359 epoch 22 - iter 345/693 - loss 0.08689047\n",
      "2019-05-13 12:02:24,553 epoch 22 - iter 414/693 - loss 0.08953329\n",
      "2019-05-13 12:02:39,753 epoch 22 - iter 483/693 - loss 0.08955839\n",
      "2019-05-13 12:02:59,433 epoch 22 - iter 552/693 - loss 0.09009214\n",
      "2019-05-13 12:03:20,714 epoch 22 - iter 621/693 - loss 0.09374351\n",
      "2019-05-13 12:03:43,288 epoch 22 - iter 690/693 - loss 0.09789657\n",
      "2019-05-13 12:03:43,600 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 12:03:43,601 EPOCH 22 done: loss 0.0978 - lr 0.0500 - bad epochs 0\n",
      "2019-05-13 12:04:42,398 DEV  : loss 0.09914688 - f-score 0.5607 - acc 0.3895\n",
      "2019-05-13 12:05:44,968 TEST : loss 0.08383900 - f-score 0.5318 - acc 0.3622\n",
      "2019-05-13 12:05:57,634 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 12:05:57,792 epoch 23 - iter 0/693 - loss 0.03360987\n",
      "2019-05-13 12:06:18,979 epoch 23 - iter 69/693 - loss 0.05630281\n",
      "2019-05-13 12:06:41,774 epoch 23 - iter 138/693 - loss 0.08172260\n",
      "2019-05-13 12:07:00,461 epoch 23 - iter 207/693 - loss 0.08916665\n",
      "2019-05-13 12:07:18,548 epoch 23 - iter 276/693 - loss 0.08101528\n",
      "2019-05-13 12:07:40,842 epoch 23 - iter 345/693 - loss 0.08134298\n",
      "2019-05-13 12:08:05,144 epoch 23 - iter 414/693 - loss 0.08512507\n",
      "2019-05-13 12:08:29,399 epoch 23 - iter 483/693 - loss 0.09139307\n",
      "2019-05-13 12:08:53,305 epoch 23 - iter 552/693 - loss 0.08648571\n",
      "2019-05-13 12:09:16,565 epoch 23 - iter 621/693 - loss 0.08842037\n",
      "2019-05-13 12:09:42,646 epoch 23 - iter 690/693 - loss 0.08971265\n",
      "2019-05-13 12:09:43,549 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 12:09:43,551 EPOCH 23 done: loss 0.0895 - lr 0.0500 - bad epochs 0\n",
      "2019-05-13 12:10:41,334 DEV  : loss 0.11259574 - f-score 0.4868 - acc 0.3217\n",
      "2019-05-13 12:11:42,593 TEST : loss 0.08748082 - f-score 0.5224 - acc 0.3536\n",
      "2019-05-13 12:11:55,935 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 12:11:56,191 epoch 24 - iter 0/693 - loss 0.16836941\n",
      "2019-05-13 12:12:18,943 epoch 24 - iter 69/693 - loss 0.07585062\n",
      "2019-05-13 12:12:37,284 epoch 24 - iter 138/693 - loss 0.09364339\n",
      "2019-05-13 12:12:59,698 epoch 24 - iter 207/693 - loss 0.09750931\n",
      "2019-05-13 12:13:21,039 epoch 24 - iter 276/693 - loss 0.09662857\n",
      "2019-05-13 12:13:45,037 epoch 24 - iter 345/693 - loss 0.09811546\n",
      "2019-05-13 12:14:06,768 epoch 24 - iter 414/693 - loss 0.09848483\n",
      "2019-05-13 12:14:29,867 epoch 24 - iter 483/693 - loss 0.09756900\n",
      "2019-05-13 12:14:52,830 epoch 24 - iter 552/693 - loss 0.09628137\n",
      "2019-05-13 12:15:16,196 epoch 24 - iter 621/693 - loss 0.09299700\n",
      "2019-05-13 12:15:39,248 epoch 24 - iter 690/693 - loss 0.09414309\n",
      "2019-05-13 12:15:39,764 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 12:15:39,766 EPOCH 24 done: loss 0.0939 - lr 0.0500 - bad epochs 0\n",
      "2019-05-13 12:16:38,563 DEV  : loss 0.12274200 - f-score 0.4923 - acc 0.3265\n",
      "2019-05-13 12:17:41,363 TEST : loss 0.09771071 - f-score 0.5120 - acc 0.3440\n",
      "2019-05-13 12:17:47,715 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-13 12:17:48,014 epoch 25 - iter 0/693 - loss 0.00057256\n",
      "2019-05-13 12:18:10,271 epoch 25 - iter 69/693 - loss 0.08126909\n",
      "2019-05-13 12:18:32,819 epoch 25 - iter 138/693 - loss 0.08774951\n",
      "2019-05-13 12:18:56,832 epoch 25 - iter 207/693 - loss 0.09532425\n",
      "2019-05-13 12:19:22,519 epoch 25 - iter 276/693 - loss 0.09460067\n",
      "2019-05-13 12:19:47,433 epoch 25 - iter 345/693 - loss 0.09693840\n",
      "2019-05-13 12:20:10,889 epoch 25 - iter 414/693 - loss 0.09924233\n",
      "2019-05-13 12:20:35,581 epoch 25 - iter 483/693 - loss 0.09494375\n",
      "2019-05-13 12:20:58,360 epoch 25 - iter 552/693 - loss 0.09401099\n"
     ]
    }
   ],
   "source": [
    "taggers = {}\n",
    "\n",
    "for pathology in ('HYPERTENSION', 'CAD', 'DIABETES'):\n",
    "    print(pathology)\n",
    "    \n",
    "    taggers[pathology] = train_tagger(pathology, embeddings, f'flair_{pathology.lower()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vadim_ml.metrics import binary_classification_report\n",
    "from vadim_ml.io import load_file\n",
    "\n",
    "def detection_report(model_name, text=True):\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for sentence in load_file(f'../models/{model_name}/test.tsv').split('\\n\\n'):\n",
    "        true_bio_tags = []\n",
    "        pred_bio_tags = []\n",
    "        \n",
    "        for token in sentence.split('\\n'):\n",
    "            if token:\n",
    "                word, true, pred, prob = token.split(' ')\n",
    "\n",
    "                true_bio_tags.append(true)\n",
    "                pred_bio_tags.append(pred)                \n",
    "\n",
    "        y_true.append('B' in true_bio_tags)\n",
    "        y_pred.append('B' in pred_bio_tags)\n",
    "            \n",
    "    return binary_classification_report(y_true, y_pred, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true negatives: 7161\n",
      "false positives: 28\n",
      "false negatives: 91\n",
      "true positives: 149\n",
      "kappa: 0.7065812615149436\n",
      "precision: 0.8418079096045198\n",
      "recall: 0.6208333333333333\n",
      "f1: 0.7146282973621104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(detection_report('flair_hypertension'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true negatives: 7219\n",
      "false positives: 40\n",
      "false negatives: 73\n",
      "true positives: 97\n",
      "kappa: 0.624247635425623\n",
      "precision: 0.708029197080292\n",
      "recall: 0.5705882352941176\n",
      "f1: 0.6319218241042346\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(detection_report('flair_cad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true negatives: 7179\n",
      "false positives: 34\n",
      "false negatives: 38\n",
      "true positives: 178\n",
      "kappa: 0.8267865446815904\n",
      "precision: 0.839622641509434\n",
      "recall: 0.8240740740740741\n",
      "f1: 0.8317757009345794\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(detection_report('flair_diabetes'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing out different model parameters and embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embeddings',\n",
       " 'hidden_size',\n",
       " 'rnn_layers',\n",
       " 'use_crf',\n",
       " 'use_rnn',\n",
       " 'dropout',\n",
       " 'locked_dropout',\n",
       " 'word_dropout']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from flair.hyperparameter.parameter import SEQUENCE_TAGGER_PARAMETERS\n",
    "\n",
    "SEQUENCE_TAGGER_PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.hyperparameter.param_selection import SearchSpace, Parameter\n",
    "from flair.embeddings import BertEmbeddings, ELMoEmbeddings, WordEmbeddings, BytePairEmbeddings, FlairEmbeddings, StackedEmbeddings\n",
    "\n",
    "embeddings_to_try = {\n",
    "    'fasttext': lambda: WordEmbeddings('en'),\n",
    "    'elmo-general': lambda: ELMoEmbeddings('original'),\n",
    "    'elmo-pubmed': lambda: ELMoEmbeddings('pubmed')\n",
    "    # Not enough memory\n",
    "    #'bert': lambda: BertEmbeddings('bert-base-cased'),\n",
    "    #'bert-elmo-pubmed': lambda: StackedEmbeddings([ BertEmbeddings('bert-base-cased'), ELMoEmbeddings('pubmed') ]),\n",
    "    #'bert-flair-pubmed': lambda: StackedEmbeddings([ BertEmbeddings('bert-base-cased'), FlairEmbeddings('pubmed-forward'), FlairEmbeddings('pubmed-backward')])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model for CAD with elmo-general embeddings\n",
      "2019-05-22 10:42:33,641 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 10:42:33,642 Evaluation method: MICRO_F1_SCORE\n",
      "2019-05-22 10:42:33,644 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 10:42:34,452 epoch 1 - iter 0/693 - loss 5.73918247\n",
      "2019-05-22 10:43:33,042 epoch 1 - iter 69/693 - loss 0.82185352\n",
      "2019-05-22 10:44:26,810 epoch 1 - iter 138/693 - loss 0.75585596\n",
      "2019-05-22 10:45:23,071 epoch 1 - iter 207/693 - loss 0.77252042\n",
      "2019-05-22 10:46:13,118 epoch 1 - iter 276/693 - loss 0.71987132\n",
      "2019-05-22 10:47:06,179 epoch 1 - iter 345/693 - loss 0.69413630\n",
      "2019-05-22 10:47:55,838 epoch 1 - iter 414/693 - loss 0.69111095\n",
      "2019-05-22 10:48:42,006 epoch 1 - iter 483/693 - loss 0.64716698\n",
      "2019-05-22 10:49:36,169 epoch 1 - iter 552/693 - loss 0.62729253\n",
      "2019-05-22 10:50:18,803 epoch 1 - iter 621/693 - loss 0.60474965\n",
      "2019-05-22 10:51:12,970 epoch 1 - iter 690/693 - loss 0.60379014\n",
      "2019-05-22 10:51:14,113 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 10:51:14,116 EPOCH 1 done: loss 0.6029 - lr 0.1000 - bad epochs 0\n",
      "2019-05-22 10:53:34,237 DEV  : loss 0.49887621 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-22 10:56:04,894 TEST : loss 0.39862001 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-22 10:56:10,071 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 10:56:10,288 epoch 2 - iter 0/693 - loss 0.54336494\n",
      "2019-05-22 10:56:29,195 epoch 2 - iter 69/693 - loss 0.37721476\n",
      "2019-05-22 10:56:53,079 epoch 2 - iter 138/693 - loss 0.40472050\n",
      "2019-05-22 10:57:15,042 epoch 2 - iter 207/693 - loss 0.41646554\n",
      "2019-05-22 10:57:41,498 epoch 2 - iter 276/693 - loss 0.42684070\n",
      "2019-05-22 10:58:01,598 epoch 2 - iter 345/693 - loss 0.39828091\n",
      "2019-05-22 10:58:23,959 epoch 2 - iter 414/693 - loss 0.42349937\n",
      "2019-05-22 10:58:48,049 epoch 2 - iter 483/693 - loss 0.42431888\n",
      "2019-05-22 10:59:10,029 epoch 2 - iter 552/693 - loss 0.41929761\n",
      "2019-05-22 10:59:33,003 epoch 2 - iter 621/693 - loss 0.41040909\n",
      "2019-05-22 10:59:53,232 epoch 2 - iter 690/693 - loss 0.39944695\n",
      "2019-05-22 10:59:53,705 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 10:59:53,707 EPOCH 2 done: loss 0.3985 - lr 0.1000 - bad epochs 0\n",
      "2019-05-22 11:00:49,485 DEV  : loss 0.55015975 - f-score 0.0000 - acc 0.0000\n",
      "2019-05-22 11:01:48,979 TEST : loss 0.43325138 - f-score 0.0048 - acc 0.0024\n",
      "2019-05-22 11:01:54,687 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:01:54,926 epoch 3 - iter 0/693 - loss 0.00066131\n",
      "2019-05-22 11:02:20,220 epoch 3 - iter 69/693 - loss 0.37095838\n",
      "2019-05-22 11:02:41,138 epoch 3 - iter 138/693 - loss 0.35406801\n",
      "2019-05-22 11:02:59,202 epoch 3 - iter 207/693 - loss 0.34677968\n",
      "2019-05-22 11:03:15,749 epoch 3 - iter 276/693 - loss 0.33201496\n",
      "2019-05-22 11:03:39,029 epoch 3 - iter 345/693 - loss 0.34717237\n",
      "2019-05-22 11:04:00,443 epoch 3 - iter 414/693 - loss 0.34551814\n",
      "2019-05-22 11:04:22,654 epoch 3 - iter 483/693 - loss 0.34080364\n",
      "2019-05-22 11:04:43,826 epoch 3 - iter 552/693 - loss 0.33927374\n",
      "2019-05-22 11:05:05,103 epoch 3 - iter 621/693 - loss 0.34536869\n",
      "2019-05-22 11:05:27,350 epoch 3 - iter 690/693 - loss 0.34372809\n",
      "2019-05-22 11:05:28,108 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:05:28,110 EPOCH 3 done: loss 0.3455 - lr 0.1000 - bad epochs 0\n",
      "2019-05-22 11:06:22,335 DEV  : loss 0.34914106 - f-score 0.2300 - acc 0.1299\n",
      "2019-05-22 11:07:20,398 TEST : loss 0.28893313 - f-score 0.1970 - acc 0.1092\n",
      "2019-05-22 11:07:26,244 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:07:26,414 epoch 4 - iter 0/693 - loss 0.00153315\n",
      "2019-05-22 11:07:44,881 epoch 4 - iter 69/693 - loss 0.36416339\n",
      "2019-05-22 11:08:01,878 epoch 4 - iter 138/693 - loss 0.33537469\n",
      "2019-05-22 11:08:17,892 epoch 4 - iter 207/693 - loss 0.33214610\n",
      "2019-05-22 11:08:35,417 epoch 4 - iter 276/693 - loss 0.32958813\n",
      "2019-05-22 11:08:53,072 epoch 4 - iter 345/693 - loss 0.31019734\n",
      "2019-05-22 11:09:12,561 epoch 4 - iter 414/693 - loss 0.30740508\n",
      "2019-05-22 11:09:30,903 epoch 4 - iter 483/693 - loss 0.30617959\n",
      "2019-05-22 11:09:54,983 epoch 4 - iter 552/693 - loss 0.30916612\n",
      "2019-05-22 11:10:18,121 epoch 4 - iter 621/693 - loss 0.30819940\n",
      "2019-05-22 11:10:40,313 epoch 4 - iter 690/693 - loss 0.30714494\n",
      "2019-05-22 11:10:40,704 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:10:40,705 EPOCH 4 done: loss 0.3095 - lr 0.1000 - bad epochs 0\n",
      "2019-05-22 11:11:37,100 DEV  : loss 0.35129103 - f-score 0.0480 - acc 0.0246\n",
      "2019-05-22 11:12:37,001 TEST : loss 0.28721902 - f-score 0.0445 - acc 0.0228\n",
      "2019-05-22 11:12:42,464 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:12:42,671 epoch 5 - iter 0/693 - loss 0.22864366\n",
      "2019-05-22 11:13:02,301 epoch 5 - iter 69/693 - loss 0.31538658\n",
      "2019-05-22 11:13:26,514 epoch 5 - iter 138/693 - loss 0.38144594\n",
      "2019-05-22 11:13:47,877 epoch 5 - iter 207/693 - loss 0.34283027\n",
      "2019-05-22 11:14:09,729 epoch 5 - iter 276/693 - loss 0.33648240\n",
      "2019-05-22 11:14:29,616 epoch 5 - iter 345/693 - loss 0.31964656\n",
      "2019-05-22 11:14:51,899 epoch 5 - iter 414/693 - loss 0.31647708\n",
      "2019-05-22 11:15:12,977 epoch 5 - iter 483/693 - loss 0.30239870\n",
      "2019-05-22 11:15:38,922 epoch 5 - iter 552/693 - loss 0.31049895\n",
      "2019-05-22 11:16:00,736 epoch 5 - iter 621/693 - loss 0.30012471\n",
      "2019-05-22 11:16:23,970 epoch 5 - iter 690/693 - loss 0.29798147\n",
      "2019-05-22 11:16:24,362 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:16:24,363 EPOCH 5 done: loss 0.2984 - lr 0.1000 - bad epochs 0\n",
      "2019-05-22 11:17:22,446 DEV  : loss 0.22769754 - f-score 0.2348 - acc 0.1330\n",
      "2019-05-22 11:18:22,572 TEST : loss 0.19198096 - f-score 0.1243 - acc 0.0663\n",
      "2019-05-22 11:18:28,891 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:18:29,162 epoch 6 - iter 0/693 - loss 0.00242639\n",
      "2019-05-22 11:18:50,710 epoch 6 - iter 69/693 - loss 0.25797090\n",
      "2019-05-22 11:19:10,576 epoch 6 - iter 138/693 - loss 0.25391554\n",
      "2019-05-22 11:19:34,800 epoch 6 - iter 207/693 - loss 0.24891347\n",
      "2019-05-22 11:19:57,572 epoch 6 - iter 276/693 - loss 0.25232257\n",
      "2019-05-22 11:20:19,170 epoch 6 - iter 345/693 - loss 0.26860544\n",
      "2019-05-22 11:20:44,001 epoch 6 - iter 414/693 - loss 0.26466166\n",
      "2019-05-22 11:21:06,966 epoch 6 - iter 483/693 - loss 0.27712168\n",
      "2019-05-22 11:21:26,950 epoch 6 - iter 552/693 - loss 0.28163891\n",
      "2019-05-22 11:21:49,091 epoch 6 - iter 621/693 - loss 0.27373325\n",
      "2019-05-22 11:22:11,681 epoch 6 - iter 690/693 - loss 0.26566866\n",
      "2019-05-22 11:22:12,028 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:22:12,031 EPOCH 6 done: loss 0.2651 - lr 0.1000 - bad epochs 0\n",
      "2019-05-22 11:23:08,093 DEV  : loss 0.28514630 - f-score 0.2727 - acc 0.1579\n",
      "2019-05-22 11:24:07,770 TEST : loss 0.23610947 - f-score 0.2602 - acc 0.1496\n",
      "2019-05-22 11:24:13,142 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:24:13,382 epoch 7 - iter 0/693 - loss 0.00258517\n",
      "2019-05-22 11:24:36,154 epoch 7 - iter 69/693 - loss 0.20737847\n",
      "2019-05-22 11:24:57,904 epoch 7 - iter 138/693 - loss 0.31632733\n",
      "2019-05-22 11:25:19,442 epoch 7 - iter 207/693 - loss 0.34038116\n",
      "2019-05-22 11:25:38,550 epoch 7 - iter 276/693 - loss 0.30313825\n",
      "2019-05-22 11:26:00,382 epoch 7 - iter 345/693 - loss 0.28867604\n",
      "2019-05-22 11:26:25,071 epoch 7 - iter 414/693 - loss 0.28507977\n",
      "2019-05-22 11:26:48,272 epoch 7 - iter 483/693 - loss 0.28056472\n",
      "2019-05-22 11:27:11,708 epoch 7 - iter 552/693 - loss 0.28168358\n",
      "2019-05-22 11:27:32,372 epoch 7 - iter 621/693 - loss 0.28300340\n",
      "2019-05-22 11:27:54,451 epoch 7 - iter 690/693 - loss 0.27850121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-22 11:27:54,955 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:27:54,957 EPOCH 7 done: loss 0.2796 - lr 0.1000 - bad epochs 0\n",
      "2019-05-22 11:28:50,305 DEV  : loss 0.21456926 - f-score 0.3457 - acc 0.2090\n",
      "2019-05-22 11:29:49,171 TEST : loss 0.18661231 - f-score 0.2729 - acc 0.1580\n",
      "2019-05-22 11:29:51,654 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-22 11:29:51,823 epoch 8 - iter 0/693 - loss 0.46480909\n",
      "2019-05-22 11:30:12,799 epoch 8 - iter 69/693 - loss 0.29046286\n",
      "2019-05-22 11:30:37,217 epoch 8 - iter 138/693 - loss 0.26829081\n"
     ]
    }
   ],
   "source": [
    "from flair.models import SequenceTagger\n",
    "from flair.trainers import ModelTrainer\n",
    "from flair.training_utils import EvaluationMetric\n",
    "\n",
    "for pathology in ('HYPERTENSION', 'CAD', 'DIABETES'):\n",
    "    for emb_name, emb in embeddings_to_try.items():\n",
    "        \n",
    "        print(f'Training the model for {pathology} with {emb_name} embeddings')\n",
    "\n",
    "        train_tagger(pathology, emb(), f'hyperopt/{emb_name}_{pathology.lower()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-31 10:45:29,651 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 10:45:29,652 Evaluation method: MICRO_F1_SCORE\n",
      "2019-05-31 10:45:29,654 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 10:45:30,105 epoch 1 - iter 0/693 - loss 33.67508698\n",
      "2019-05-31 10:46:28,618 epoch 1 - iter 69/693 - loss 1.69672735\n",
      "2019-05-31 10:47:28,012 epoch 1 - iter 138/693 - loss 1.03634923\n",
      "2019-05-31 10:48:27,931 epoch 1 - iter 207/693 - loss 0.83066240\n",
      "2019-05-31 10:49:14,354 epoch 1 - iter 276/693 - loss 0.77436809\n",
      "2019-05-31 10:50:14,665 epoch 1 - iter 345/693 - loss 0.70632665\n",
      "2019-05-31 10:51:08,388 epoch 1 - iter 414/693 - loss 0.68452465\n",
      "2019-05-31 10:52:05,456 epoch 1 - iter 483/693 - loss 0.64053016\n",
      "2019-05-31 10:52:51,041 epoch 1 - iter 552/693 - loss 0.64900328\n",
      "2019-05-31 10:53:35,174 epoch 1 - iter 621/693 - loss 0.61229206\n",
      "2019-05-31 10:54:17,447 epoch 1 - iter 690/693 - loss 0.58021638\n",
      "2019-05-31 10:54:18,226 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 10:54:18,228 EPOCH 1 done: loss 0.5796 - lr 0.1000 - bad epochs 0\n",
      "2019-05-31 10:56:45,528 DEV  : loss 0.17845915 - f-score 0.3589 - acc 0.2188\n",
      "2019-05-31 10:59:29,656 TEST : loss 0.18153936 - f-score 0.3504 - acc 0.2124\n",
      "2019-05-31 10:59:34,831 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 10:59:35,099 epoch 2 - iter 0/693 - loss 0.07077774\n",
      "2019-05-31 10:59:57,006 epoch 2 - iter 69/693 - loss 0.26371123\n",
      "2019-05-31 11:00:21,447 epoch 2 - iter 138/693 - loss 0.38254212\n",
      "2019-05-31 11:00:37,948 epoch 2 - iter 207/693 - loss 0.32476070\n",
      "2019-05-31 11:00:58,352 epoch 2 - iter 276/693 - loss 0.31590173\n",
      "2019-05-31 11:01:15,545 epoch 2 - iter 345/693 - loss 0.29593626\n",
      "2019-05-31 11:01:32,447 epoch 2 - iter 414/693 - loss 0.30298898\n",
      "2019-05-31 11:01:50,034 epoch 2 - iter 483/693 - loss 0.29948242\n",
      "2019-05-31 11:02:08,472 epoch 2 - iter 552/693 - loss 0.30287838\n",
      "2019-05-31 11:02:28,499 epoch 2 - iter 621/693 - loss 0.29213662\n",
      "2019-05-31 11:02:47,514 epoch 2 - iter 690/693 - loss 0.29197711\n",
      "2019-05-31 11:02:48,059 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:02:48,062 EPOCH 2 done: loss 0.2917 - lr 0.1000 - bad epochs 0\n",
      "2019-05-31 11:03:49,668 DEV  : loss 0.16525035 - f-score 0.4564 - acc 0.2957\n",
      "2019-05-31 11:04:54,983 TEST : loss 0.16853444 - f-score 0.5041 - acc 0.3370\n",
      "2019-05-31 11:05:00,194 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:05:00,654 epoch 3 - iter 0/693 - loss 0.38726562\n",
      "2019-05-31 11:05:24,908 epoch 3 - iter 69/693 - loss 0.23719753\n",
      "2019-05-31 11:05:48,364 epoch 3 - iter 138/693 - loss 0.24011819\n",
      "2019-05-31 11:06:08,339 epoch 3 - iter 207/693 - loss 0.23799008\n",
      "2019-05-31 11:06:30,893 epoch 3 - iter 276/693 - loss 0.23857461\n",
      "2019-05-31 11:06:54,522 epoch 3 - iter 345/693 - loss 0.25200946\n",
      "2019-05-31 11:07:16,000 epoch 3 - iter 414/693 - loss 0.24002385\n",
      "2019-05-31 11:07:34,352 epoch 3 - iter 483/693 - loss 0.23601929\n",
      "2019-05-31 11:07:55,566 epoch 3 - iter 552/693 - loss 0.23583891\n",
      "2019-05-31 11:08:18,399 epoch 3 - iter 621/693 - loss 0.25184003\n",
      "2019-05-31 11:08:36,537 epoch 3 - iter 690/693 - loss 0.25791537\n",
      "2019-05-31 11:08:36,833 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:08:36,835 EPOCH 3 done: loss 0.2577 - lr 0.1000 - bad epochs 0\n",
      "2019-05-31 11:09:36,765 DEV  : loss 0.11672551 - f-score 0.6032 - acc 0.4319\n",
      "2019-05-31 11:10:40,468 TEST : loss 0.11721568 - f-score 0.5897 - acc 0.4182\n",
      "2019-05-31 11:10:46,110 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:10:46,413 epoch 4 - iter 0/693 - loss 0.00761545\n",
      "2019-05-31 11:11:11,473 epoch 4 - iter 69/693 - loss 0.39260087\n",
      "2019-05-31 11:11:35,933 epoch 4 - iter 138/693 - loss 0.31912361\n",
      "2019-05-31 11:11:55,604 epoch 4 - iter 207/693 - loss 0.29985875\n",
      "2019-05-31 11:12:17,593 epoch 4 - iter 276/693 - loss 0.26691288\n",
      "2019-05-31 11:12:39,940 epoch 4 - iter 345/693 - loss 0.24818431\n",
      "2019-05-31 11:13:02,595 epoch 4 - iter 414/693 - loss 0.23164503\n",
      "2019-05-31 11:13:24,962 epoch 4 - iter 483/693 - loss 0.24059560\n",
      "2019-05-31 11:13:40,720 epoch 4 - iter 552/693 - loss 0.24600238\n",
      "2019-05-31 11:14:03,539 epoch 4 - iter 621/693 - loss 0.23967880\n",
      "2019-05-31 11:14:26,892 epoch 4 - iter 690/693 - loss 0.23660235\n",
      "2019-05-31 11:14:27,426 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:14:27,427 EPOCH 4 done: loss 0.2373 - lr 0.1000 - bad epochs 0\n",
      "2019-05-31 11:15:26,525 DEV  : loss 0.17073201 - f-score 0.3922 - acc 0.2440\n",
      "2019-05-31 11:16:31,046 TEST : loss 0.17255762 - f-score 0.3771 - acc 0.2324\n",
      "2019-05-31 11:16:36,383 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:16:36,650 epoch 5 - iter 0/693 - loss 0.08782691\n",
      "2019-05-31 11:16:59,039 epoch 5 - iter 69/693 - loss 0.15654410\n",
      "2019-05-31 11:17:18,989 epoch 5 - iter 138/693 - loss 0.19066150\n",
      "2019-05-31 11:17:41,037 epoch 5 - iter 207/693 - loss 0.19129687\n",
      "2019-05-31 11:18:02,704 epoch 5 - iter 276/693 - loss 0.21975809\n",
      "2019-05-31 11:18:24,973 epoch 5 - iter 345/693 - loss 0.23367521\n",
      "2019-05-31 11:18:50,872 epoch 5 - iter 414/693 - loss 0.26509773\n",
      "2019-05-31 11:19:11,381 epoch 5 - iter 483/693 - loss 0.26224683\n",
      "2019-05-31 11:19:29,301 epoch 5 - iter 552/693 - loss 0.27396403\n",
      "2019-05-31 11:19:48,138 epoch 5 - iter 621/693 - loss 0.25892380\n",
      "2019-05-31 11:20:07,457 epoch 5 - iter 690/693 - loss 0.26242436\n",
      "2019-05-31 11:20:07,731 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:20:07,732 EPOCH 5 done: loss 0.2619 - lr 0.1000 - bad epochs 0\n",
      "2019-05-31 11:21:07,107 DEV  : loss 0.17973776 - f-score 0.5276 - acc 0.3583\n",
      "2019-05-31 11:22:11,764 TEST : loss 0.18179809 - f-score 0.5542 - acc 0.3833\n",
      "2019-05-31 11:22:14,121 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:22:14,553 epoch 6 - iter 0/693 - loss 0.51304388\n",
      "2019-05-31 11:22:34,884 epoch 6 - iter 69/693 - loss 0.20885839\n",
      "2019-05-31 11:22:56,339 epoch 6 - iter 138/693 - loss 0.20517012\n",
      "2019-05-31 11:23:18,072 epoch 6 - iter 207/693 - loss 0.22186551\n",
      "2019-05-31 11:23:42,574 epoch 6 - iter 276/693 - loss 0.25392642\n",
      "2019-05-31 11:24:03,209 epoch 6 - iter 345/693 - loss 0.25795469\n",
      "2019-05-31 11:24:21,046 epoch 6 - iter 414/693 - loss 0.26223721\n",
      "2019-05-31 11:24:41,971 epoch 6 - iter 483/693 - loss 0.25376387\n",
      "2019-05-31 11:25:04,810 epoch 6 - iter 552/693 - loss 0.24925387\n",
      "2019-05-31 11:25:23,438 epoch 6 - iter 621/693 - loss 0.25159485\n",
      "2019-05-31 11:25:44,329 epoch 6 - iter 690/693 - loss 0.25591182\n",
      "2019-05-31 11:25:44,611 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:25:44,613 EPOCH 6 done: loss 0.2553 - lr 0.1000 - bad epochs 1\n",
      "2019-05-31 11:26:43,525 DEV  : loss 0.21991132 - f-score 0.4256 - acc 0.2704\n",
      "2019-05-31 11:27:48,431 TEST : loss 0.21989170 - f-score 0.4617 - acc 0.3002\n",
      "2019-05-31 11:27:51,127 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:27:51,491 epoch 7 - iter 0/693 - loss 0.11450624\n",
      "2019-05-31 11:28:13,670 epoch 7 - iter 69/693 - loss 0.25091370\n",
      "2019-05-31 11:28:33,570 epoch 7 - iter 138/693 - loss 0.22354126\n",
      "2019-05-31 11:28:51,925 epoch 7 - iter 207/693 - loss 0.24006493\n",
      "2019-05-31 11:29:14,176 epoch 7 - iter 276/693 - loss 0.23299588\n",
      "2019-05-31 11:29:30,091 epoch 7 - iter 345/693 - loss 0.24522864\n",
      "2019-05-31 11:29:50,079 epoch 7 - iter 414/693 - loss 0.25225985\n",
      "2019-05-31 11:30:08,896 epoch 7 - iter 483/693 - loss 0.24701108\n",
      "2019-05-31 11:30:31,776 epoch 7 - iter 552/693 - loss 0.24057172\n",
      "2019-05-31 11:30:55,639 epoch 7 - iter 621/693 - loss 0.24480511\n",
      "2019-05-31 11:31:16,557 epoch 7 - iter 690/693 - loss 0.23587109\n",
      "2019-05-31 11:31:16,983 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-31 11:31:16,986 EPOCH 7 done: loss 0.2353 - lr 0.1000 - bad epochs 2\n",
      "2019-05-31 11:32:19,887 DEV  : loss 0.19348748 - f-score 0.4019 - acc 0.2514\n",
      "2019-05-31 11:33:25,908 TEST : loss 0.19318265 - f-score 0.4696 - acc 0.3069\n",
      "2019-05-31 11:33:31,302 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:33:31,602 epoch 8 - iter 0/693 - loss 0.00890633\n",
      "2019-05-31 11:33:55,116 epoch 8 - iter 69/693 - loss 0.19240644\n",
      "2019-05-31 11:34:16,977 epoch 8 - iter 138/693 - loss 0.22215896\n",
      "2019-05-31 11:34:35,068 epoch 8 - iter 207/693 - loss 0.25610739\n",
      "2019-05-31 11:34:50,867 epoch 8 - iter 276/693 - loss 0.22425647\n",
      "2019-05-31 11:35:08,592 epoch 8 - iter 345/693 - loss 0.23474525\n",
      "2019-05-31 11:35:30,348 epoch 8 - iter 414/693 - loss 0.23975534\n",
      "2019-05-31 11:35:51,454 epoch 8 - iter 483/693 - loss 0.25055043\n",
      "2019-05-31 11:36:11,257 epoch 8 - iter 552/693 - loss 0.24791340\n",
      "2019-05-31 11:36:28,661 epoch 8 - iter 621/693 - loss 0.25373726\n",
      "2019-05-31 11:36:47,175 epoch 8 - iter 690/693 - loss 0.25361647\n",
      "2019-05-31 11:36:47,658 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:36:47,659 EPOCH 8 done: loss 0.2538 - lr 0.1000 - bad epochs 0\n",
      "2019-05-31 11:37:45,296 DEV  : loss 0.10698254 - f-score 0.5656 - acc 0.3943\n",
      "2019-05-31 11:38:49,194 TEST : loss 0.11439461 - f-score 0.5938 - acc 0.4223\n",
      "2019-05-31 11:38:51,648 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:38:51,954 epoch 9 - iter 0/693 - loss 2.67538810\n",
      "2019-05-31 11:39:13,954 epoch 9 - iter 69/693 - loss 0.16822437\n",
      "2019-05-31 11:39:37,286 epoch 9 - iter 138/693 - loss 0.17218026\n",
      "2019-05-31 11:40:01,909 epoch 9 - iter 207/693 - loss 0.20653866\n",
      "2019-05-31 11:40:28,393 epoch 9 - iter 276/693 - loss 0.20590538\n",
      "2019-05-31 11:40:52,420 epoch 9 - iter 345/693 - loss 0.21579962\n",
      "2019-05-31 11:41:15,459 epoch 9 - iter 414/693 - loss 0.21457847\n",
      "2019-05-31 11:41:38,622 epoch 9 - iter 483/693 - loss 0.22580576\n",
      "2019-05-31 11:42:00,579 epoch 9 - iter 552/693 - loss 0.21810407\n",
      "2019-05-31 11:42:20,641 epoch 9 - iter 621/693 - loss 0.23261360\n",
      "2019-05-31 11:42:41,341 epoch 9 - iter 690/693 - loss 0.23483833\n",
      "2019-05-31 11:42:42,060 ----------------------------------------------------------------------------------------------------\n",
      "2019-05-31 11:42:42,061 EPOCH 9 done: loss 0.2348 - lr 0.1000 - bad epochs 1\n",
      "2019-05-31 11:43:42,084 DEV  : loss 0.14681198 - f-score 0.5274 - acc 0.3581\n"
     ]
    }
   ],
   "source": [
    "train_tagger('DIABETES', embeddings_to_try['elmo-general'](), f'hyperopt/elmo-general_diabetes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true negatives: 7123\n",
      "false positives: 66\n",
      "false negatives: 51\n",
      "true positives: 189\n",
      "kappa: 0.7554981708629223\n",
      "precision: 0.7411764705882353\n",
      "recall: 0.7875\n",
      "f1: 0.7636363636363638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(detection_report('hyperopt/fasttext_hypertension'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true negatives: 7224\n",
      "false positives: 35\n",
      "false negatives: 72\n",
      "true positives: 98\n",
      "kappa: 0.6396251281300342\n",
      "precision: 0.7368421052631579\n",
      "recall: 0.5764705882352941\n",
      "f1: 0.6468646864686468\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(detection_report('hyperopt/fasttext_cad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true negatives: 7184\n",
      "false positives: 29\n",
      "false negatives: 47\n",
      "true positives: 169\n",
      "kappa: 0.8111736514529767\n",
      "precision: 0.8535353535353535\n",
      "recall: 0.7824074074074074\n",
      "f1: 0.8164251207729469\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(detection_report('hyperopt/fasttext_diabetes'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true negatives: 7144\n",
      "false positives: 45\n",
      "false negatives: 29\n",
      "true positives: 211\n",
      "kappa: 0.8456595124405373\n",
      "precision: 0.82421875\n",
      "recall: 0.8791666666666667\n",
      "f1: 0.8508064516129031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(detection_report('hyperopt/elmo-general_hypertension'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true negatives: 7232\n",
      "false positives: 27\n",
      "false negatives: 81\n",
      "true positives: 89\n",
      "kappa: 0.6152353622148663\n",
      "precision: 0.7672413793103449\n",
      "recall: 0.5235294117647059\n",
      "f1: 0.6223776223776224\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(detection_report('hyperopt/elmo-general_cad'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "true negatives: 7176\n",
      "false positives: 37\n",
      "false negatives: 45\n",
      "true positives: 171\n",
      "kappa: 0.8009248245120978\n",
      "precision: 0.8221153846153846\n",
      "recall: 0.7916666666666666\n",
      "f1: 0.8066037735849055\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(detection_report('hyperopt/elmo-general_diabetes'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
