{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/e0/be401c003291b56efc55aeba6a80ab790d3d4cece2778288d65323009420/pip-19.1.1-py2.py3-none-any.whl (1.4MB)\n",
      "\u001b[K    100% |████████████████████████████████| 1.4MB 3.4MB/s \n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Found existing installation: pip 18.1\n",
      "    Uninstalling pip-18.1:\n",
      "      Successfully uninstalled pip-18.1\n",
      "Successfully installed pip-19.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting seqeval[gpu]\n",
      "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
      "Requirement already satisfied: numpy>=1.14.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from seqeval[gpu]) (1.15.4)\n",
      "Requirement already satisfied: Keras>=2.2.4 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from seqeval[gpu]) (2.2.4)\n",
      "Requirement already satisfied: tensorflow-gpu in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from seqeval[gpu]) (1.12.0)\n",
      "Requirement already satisfied: scipy>=0.14 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.1.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.0.5 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.0.5)\n",
      "Requirement already satisfied: h5py in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (2.8.0)\n",
      "Requirement already satisfied: keras-applications>=1.0.6 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.0.6)\n",
      "Requirement already satisfied: pyyaml in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (3.13)\n",
      "Requirement already satisfied: six>=1.9.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from Keras>=2.2.4->seqeval[gpu]) (1.11.0)\n",
      "Requirement already satisfied: protobuf>=3.6.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorflow-gpu->seqeval[gpu]) (3.6.1)\n",
      "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorflow-gpu->seqeval[gpu]) (1.12.0)\n",
      "Requirement already satisfied: astor>=0.6.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorflow-gpu->seqeval[gpu]) (0.7.1)\n",
      "Requirement already satisfied: grpcio>=1.8.6 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorflow-gpu->seqeval[gpu]) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorflow-gpu->seqeval[gpu]) (1.1.0)\n",
      "Requirement already satisfied: gast>=0.2.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorflow-gpu->seqeval[gpu]) (0.2.0)\n",
      "Requirement already satisfied: wheel>=0.26 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorflow-gpu->seqeval[gpu]) (0.32.3)\n",
      "Requirement already satisfied: absl-py>=0.1.6 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorflow-gpu->seqeval[gpu]) (0.6.1)\n",
      "Requirement already satisfied: setuptools in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from protobuf>=3.6.1->tensorflow-gpu->seqeval[gpu]) (39.0.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.10 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu->seqeval[gpu]) (0.14.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow-gpu->seqeval[gpu]) (3.0.1)\n",
      "Building wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
      "Successfully built seqeval\n",
      "Installing collected packages: seqeval\n",
      "Successfully installed seqeval-0.0.12\n"
     ]
    }
   ],
   "source": [
    "!pip install seqeval[gpu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting i2b2_import\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/17/ee0138e4e44b37c031861824abb61a6a290f8883a61d490608cb8dfd0e39/i2b2_import-1.6.3-py3-none-any.whl\n",
      "Collecting psycopg2>=2.7.1 (from i2b2_import)\n",
      "  Using cached https://files.pythonhosted.org/packages/5c/1c/6997288da181277a0c29bc39a5f9143ff20b8c99f2a7d059cfb55163e165/psycopg2-2.8.3.tar.gz\n",
      "\u001b[31m    ERROR: Complete output from command python setup.py egg_info:\u001b[0m\n",
      "\u001b[31m    ERROR: running egg_info\n",
      "    creating pip-egg-info/psycopg2.egg-info\n",
      "    writing pip-egg-info/psycopg2.egg-info/PKG-INFO\n",
      "    writing dependency_links to pip-egg-info/psycopg2.egg-info/dependency_links.txt\n",
      "    writing top-level names to pip-egg-info/psycopg2.egg-info/top_level.txt\n",
      "    writing manifest file 'pip-egg-info/psycopg2.egg-info/SOURCES.txt'\n",
      "    \n",
      "    Error: pg_config executable not found.\n",
      "    \n",
      "    pg_config is required to build psycopg2 from source.  Please add the directory\n",
      "    containing pg_config to the $PATH or specify the full executable path with the\n",
      "    option:\n",
      "    \n",
      "        python setup.py build_ext --pg-config /path/to/pg_config build ...\n",
      "    \n",
      "    or with the pg_config option in 'setup.cfg'.\n",
      "    \n",
      "    If you prefer to avoid building psycopg2 from source, please install the PyPI\n",
      "    'psycopg2-binary' package instead.\n",
      "    \n",
      "    For further information please check the 'doc/src/install.rst' file (also at\n",
      "    <http://initd.org/psycopg/docs/install.html>).\n",
      "    \n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command \"python setup.py egg_info\" failed with error code 1 in /tmp/pip-install-0oqd12dk/psycopg2/\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install i2b2_import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: pytorch-pretrained-bert\n",
      "Version: 0.6.2\n",
      "Summary: PyTorch version of Google AI BERT model with script to load Google pre-trained models\n",
      "Home-page: https://github.com/huggingface/pytorch-pretrained-BERT\n",
      "Author: Thomas Wolf, Victor Sanh, Tim Rault, Google AI Language Team Authors, Open AI team Authors\n",
      "Author-email: thomas@huggingface.co\n",
      "License: Apache\n",
      "Location: /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages\n",
      "Requires: tqdm, numpy, requests, boto3, regex, torch\n",
      "Required-by: flair\n"
     ]
    }
   ],
   "source": [
    "!pip show pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pytorch-pretrained-bert==0.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/95/68/84de54aea460eb5b2e90bf47a429aacc1ce97ff052ec40874ea38ae2331d/pytorch_pretrained_bert-0.4.0-py3-none-any.whl (45kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 629kB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytorch-pretrained-bert==0.4.0) (1.15.4)\n",
      "Requirement already satisfied: tqdm in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytorch-pretrained-bert==0.4.0) (4.28.1)\n",
      "Requirement already satisfied: torch>=0.4.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytorch-pretrained-bert==0.4.0) (1.1.0)\n",
      "Requirement already satisfied: boto3 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytorch-pretrained-bert==0.4.0) (1.9.59)\n",
      "Requirement already satisfied: requests in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pytorch-pretrained-bert==0.4.0) (2.20.1)\n",
      "Requirement already satisfied: botocore<1.13.0,>=1.12.59 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert==0.4.0) (1.12.59)\n",
      "Requirement already satisfied: s3transfer<0.2.0,>=0.1.10 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert==0.4.0) (0.1.13)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from boto3->pytorch-pretrained-bert==0.4.0) (0.9.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert==0.4.0) (3.0.4)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert==0.4.0) (2.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert==0.4.0) (2018.11.29)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from requests->pytorch-pretrained-bert==0.4.0) (1.24.1)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.59->boto3->pytorch-pretrained-bert==0.4.0) (2.7.5)\n",
      "Requirement already satisfied: docutils>=0.10 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from botocore<1.13.0,>=1.12.59->boto3->pytorch-pretrained-bert==0.4.0) (0.14)\n",
      "Requirement already satisfied: six>=1.5 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.59->boto3->pytorch-pretrained-bert==0.4.0) (1.11.0)\n",
      "\u001b[31mERROR: flair 0.4.2 has requirement pytorch-pretrained-bert>=0.6.1, but you'll have pytorch-pretrained-bert 0.4.0 which is incompatible.\u001b[0m\n",
      "Installing collected packages: pytorch-pretrained-bert\n",
      "  Found existing installation: pytorch-pretrained-bert 0.6.2\n",
      "    Uninstalling pytorch-pretrained-bert-0.6.2:\n",
      "      Successfully uninstalled pytorch-pretrained-bert-0.6.2\n",
      "Successfully installed pytorch-pretrained-bert-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch-pretrained-bert==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/IINemo/libact.git@seq\n",
      "  Cloning https://github.com/IINemo/libact.git (to revision seq) to /tmp/pip-req-build-i0yb8va9\n",
      "  Running command git clone -q https://github.com/IINemo/libact.git /tmp/pip-req-build-i0yb8va9\n",
      "  Running command git checkout -b seq --track origin/seq\n",
      "  Switched to a new branch 'seq'\n",
      "  Branch seq set up to track remote branch seq from origin.\n",
      "Requirement already satisfied (use --upgrade to upgrade): libact==0.1.3b0 from git+https://github.com/IINemo/libact.git@seq in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages\n",
      "Requirement already satisfied: numpy in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from libact==0.1.3b0) (1.15.4)\n",
      "Requirement already satisfied: scipy in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from libact==0.1.3b0) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from libact==0.1.3b0) (0.20.1)\n",
      "Requirement already satisfied: Cython in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from libact==0.1.3b0) (0.29.1)\n",
      "Requirement already satisfied: joblib in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from libact==0.1.3b0) (0.13.0)\n",
      "Requirement already satisfied: six in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from libact==0.1.3b0) (1.11.0)\n",
      "Building wheels for collected packages: libact\n",
      "  Building wheel for libact (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-px0vocik/wheels/43/f8/6d/9e686dbc90eb0c3a91ceee9e382e6ab85954d9a83459bced85\n",
      "Successfully built libact\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/IINemo/libact.git@seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/IINemo/active_learning_toolbox.git@seq\n",
      "  Cloning https://github.com/IINemo/active_learning_toolbox.git (to revision seq) to /tmp/pip-req-build-4a5skxiv\n",
      "  Running command git clone -q https://github.com/IINemo/active_learning_toolbox.git /tmp/pip-req-build-4a5skxiv\n",
      "  Running command git checkout -b seq --track origin/seq\n",
      "  Switched to a new branch 'seq'\n",
      "  Branch seq set up to track remote branch seq from origin.\n",
      "Requirement already satisfied (use --upgrade to upgrade): actleto==0.1.0 from git+https://github.com/IINemo/active_learning_toolbox.git@seq in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages\n",
      "Requirement already satisfied: cython in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from actleto==0.1.0) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from actleto==0.1.0) (1.15.4)\n",
      "Requirement already satisfied: pandas>=0.20.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from actleto==0.1.0) (0.23.4)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from actleto==0.1.0) (0.20.1)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from actleto==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: Pillow>=4.2.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from actleto==0.1.0) (5.3.0)\n",
      "Requirement already satisfied: ipywidgets>=4 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from actleto==0.1.0) (7.4.2)\n",
      "Requirement already satisfied: annoy in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from actleto==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: pytz>=2011k in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pandas>=0.20.1->actleto==0.1.0) (2018.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pandas>=0.20.1->actleto==0.1.0) (2.7.5)\n",
      "Requirement already satisfied: widgetsnbextension~=3.4.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipywidgets>=4->actleto==0.1.0) (3.4.2)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipywidgets>=4->actleto==0.1.0) (7.2.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipywidgets>=4->actleto==0.1.0) (4.3.2)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipywidgets>=4->actleto==0.1.0) (4.4.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipywidgets>=4->actleto==0.1.0) (5.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from python-dateutil>=2.5.0->pandas>=0.20.1->actleto==0.1.0) (1.11.0)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (5.7.2)\n",
      "Requirement already satisfied: pygments in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (2.3.0)\n",
      "Requirement already satisfied: pickleshare in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (2.0.7)\n",
      "Requirement already satisfied: backcall in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (0.1.0)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (4.6.0)\n",
      "Requirement already satisfied: decorator in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (4.3.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (0.13.1)\n",
      "Requirement already satisfied: setuptools>=18.5 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (39.0.1)\n",
      "Requirement already satisfied: ipython-genutils in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from traitlets>=4.3.1->ipywidgets>=4->actleto==0.1.0) (0.2.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets>=4->actleto==0.1.0) (2.6.0)\n",
      "Requirement already satisfied: jupyter-core in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from nbformat>=4.2.0->ipywidgets>=4->actleto==0.1.0) (4.4.0)\n",
      "Requirement already satisfied: tornado>=4.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets>=4->actleto==0.1.0) (5.1.1)\n",
      "Requirement already satisfied: jupyter-client in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from ipykernel>=4.5.1->ipywidgets>=4->actleto==0.1.0) (5.2.3)\n",
      "Requirement already satisfied: pyzmq>=17 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (17.1.2)\n",
      "Requirement already satisfied: jinja2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (2.10)\n",
      "Requirement already satisfied: nbconvert in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (5.4.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (0.8.1)\n",
      "Requirement already satisfied: prometheus-client in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (0.4.2)\n",
      "Requirement already satisfied: Send2Trash in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: wcwidth in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (0.1.7)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (0.6.0)\n",
      "Requirement already satisfied: parso>=0.3.0 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=4->actleto==0.1.0) (0.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (1.1.0)\n",
      "Requirement already satisfied: bleach in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (3.0.2)\n",
      "Requirement already satisfied: defusedxml in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (0.5.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (1.4.2)\n",
      "Requirement already satisfied: mistune>=0.8.1 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (0.8.4)\n",
      "Requirement already satisfied: testpath in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (0.4.2)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (0.2.3)\n",
      "Requirement already satisfied: webencodings in /root/.pyenv/versions/3.6.7/lib/python3.6/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.4.0->ipywidgets>=4->actleto==0.1.0) (0.5.1)\n",
      "Building wheels for collected packages: actleto\n",
      "  Building wheel for actleto (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/pip-ephem-wheel-cache-7qayn8qj/wheels/96/c0/0a/e37cee1f7228329c68c9185d15c632f7837f1ef5a863116bd8\n",
      "Successfully built actleto\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/IINemo/active_learning_toolbox.git@seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "GeForce GTX 1080 Ti\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "n_gpu = torch.cuda.device_count()\n",
    "print(n_gpu)\n",
    "for i in range(n_gpu):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('active_learning')\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fhandler = logging.FileHandler(filename='../preprosessing/conll03_active_learning.log', mode='a')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = '../workdir/models/0.4.0'\n",
    "\n",
    "MAX_LEN = 100\n",
    "#BATCH_SIZE = 105\n",
    "BATCH_SIZE = 50 \n",
    "# MAX_LEN = 150\n",
    "# BATCH_SIZE = 32\n",
    "PRED_BATCH_SIZE = 1000\n",
    "random_state = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from i2b2_utils import drop_noise_samples, tokenize_and_generate_labels, split_train_test_by_document, create_tensors, train\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertForTokenClassification, BertAdam\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14042, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>Tag</th>\n",
       "      <th>I-ORG</th>\n",
       "      <th>I-MISC</th>\n",
       "      <th>I-PER</th>\n",
       "      <th>doc_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EU rejects German call to boycott British lamb .</td>\n",
       "      <td>I-ORG O I-MISC O O O I-MISC O O</td>\n",
       "      <td>[[0, 2]]</td>\n",
       "      <td>[[11, 17], [34, 41]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>But Fischler agreed to review his proposal aft...</td>\n",
       "      <td>O I-PER O O O O O O O I-ORG O O O O O O O O O ...</td>\n",
       "      <td>[[53, 55]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[4, 12]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Port conditions from Lloyds Shipping Intellige...</td>\n",
       "      <td>O O O I-ORG I-ORG I-ORG I-ORG O</td>\n",
       "      <td>[[21, 27], [28, 36], [37, 49], [50, 57]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>SOCCER - UEFA REWARDS THREE COUNTRIES FOR FAIR...</td>\n",
       "      <td>O O I-ORG O O O O O O O</td>\n",
       "      <td>[[9, 13]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>* Conglomerate Bollore lost 2.4 percent to 521...</td>\n",
       "      <td>O O I-ORG O O O O O O O O O O O O O O O O O O ...</td>\n",
       "      <td>[[15, 22], [182, 186], [187, 193], [194, 203],...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   texts  \\\n",
       "1       EU rejects German call to boycott British lamb .   \n",
       "10     But Fischler agreed to review his proposal aft...   \n",
       "100    Port conditions from Lloyds Shipping Intellige...   \n",
       "1000   SOCCER - UEFA REWARDS THREE COUNTRIES FOR FAIR...   \n",
       "10000  * Conglomerate Bollore lost 2.4 percent to 521...   \n",
       "\n",
       "                                                     Tag  \\\n",
       "1                        I-ORG O I-MISC O O O I-MISC O O   \n",
       "10     O I-PER O O O O O O O I-ORG O O O O O O O O O ...   \n",
       "100                      O O O I-ORG I-ORG I-ORG I-ORG O   \n",
       "1000                             O O I-ORG O O O O O O O   \n",
       "10000  O O I-ORG O O O O O O O O O O O O O O O O O O ...   \n",
       "\n",
       "                                                   I-ORG  \\\n",
       "1                                               [[0, 2]]   \n",
       "10                                            [[53, 55]]   \n",
       "100             [[21, 27], [28, 36], [37, 49], [50, 57]]   \n",
       "1000                                           [[9, 13]]   \n",
       "10000  [[15, 22], [182, 186], [187, 193], [194, 203],...   \n",
       "\n",
       "                     I-MISC      I-PER  doc_ids  \n",
       "1      [[11, 17], [34, 41]]         []        1  \n",
       "10                       []  [[4, 12]]        1  \n",
       "100                      []         []        9  \n",
       "1000                     []         []       60  \n",
       "10000                    []         []      595  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '../preprosessing/all_attributes.json'\n",
    "dataset = pd.read_json(dataset_path)\n",
    "dataset.rename(index=str,columns={'Corpus':'texts'}, \n",
    "                inplace=True)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4489, 6)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_name = 'I-MISC'\n",
    "#attr_name = 'CAD'\n",
    "#attr_name = 'DIABETES'\n",
    "\n",
    "selected_dataset = drop_noise_samples(dataset, attr_name)\n",
    "selected_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_selected_dataset, test_selected_dataset = split_train_test_by_document(selected_dataset, test_ratio=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3455, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texts</th>\n",
       "      <th>Tag</th>\n",
       "      <th>I-ORG</th>\n",
       "      <th>I-MISC</th>\n",
       "      <th>I-PER</th>\n",
       "      <th>doc_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRI...</td>\n",
       "      <td>O O I-LOC O O O O I-PER O O O O</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[31, 36]]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Two goals from defensive errors in the last si...</td>\n",
       "      <td>O O O O O O O O O O O I-LOC O O O O O O O O O ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Scoreboard in the second</td>\n",
       "      <td>O O O O</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>INTERVIEW-ZYWIEC SEES NO BIG 97 NET RISE .</td>\n",
       "      <td>I-MISC O O O O O O O</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 16]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>Steven Silber</td>\n",
       "      <td>I-PER I-PER</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[[0, 6], [7, 13]]</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  texts  \\\n",
       "1     SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRI...   \n",
       "10    Two goals from defensive errors in the last si...   \n",
       "100                            Scoreboard in the second   \n",
       "1001         INTERVIEW-ZYWIEC SEES NO BIG 97 NET RISE .   \n",
       "1002                                      Steven Silber   \n",
       "\n",
       "                                                    Tag I-ORG     I-MISC  \\\n",
       "1                       O O I-LOC O O O O I-PER O O O O    []         []   \n",
       "10    O O O O O O O O O O O I-LOC O O O O O O O O O ...    []         []   \n",
       "100                                             O O O O    []         []   \n",
       "1001                               I-MISC O O O O O O O    []  [[0, 16]]   \n",
       "1002                                        I-PER I-PER    []         []   \n",
       "\n",
       "                  I-PER  doc_ids  \n",
       "1            [[31, 36]]        1  \n",
       "10                   []        1  \n",
       "100                  []        6  \n",
       "1001                 []       55  \n",
       "1002  [[0, 6], [7, 13]]       55  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_path = '../preprosessing/all_attributes_testb.json'\n",
    "dataset_test = pd.read_json(dataset_test_path)\n",
    "dataset_test.rename(index=str,columns={'Corpus':'texts'}, \n",
    "                inplace=True)\n",
    "print(dataset_test.shape)\n",
    "dataset_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (4489, 6)\n",
      "test (1088, 6)\n"
     ]
    }
   ],
   "source": [
    "test_selected_dataset = drop_noise_samples(dataset_test, attr_name)\n",
    "train_selected_dataset = selected_dataset\n",
    "print('train', selected_dataset.shape)\n",
    "print('test', test_selected_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.en.processor_tokenizer_nltk_en import ProcessorTokenizerNltkEn\n",
    "\n",
    "word_tokenizer = ProcessorTokenizerNltkEn()\n",
    "bpe_tokenizer = BertTokenizer.from_pretrained('bert-base-cased', cache_dir=CACHE_DIR, do_lower_case=False)\n",
    "train_sents, train_labels = tokenize_and_generate_labels(word_tokenizer, bpe_tokenizer, train_selected_dataset, attr_name, MAX_LEN)\n",
    "test_sents, test_labels = tokenize_and_generate_labels(word_tokenizer, bpe_tokenizer, test_selected_dataset, attr_name, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N with max lengths: 0\n",
      "Ratio: 0.0\n"
     ]
    }
   ],
   "source": [
    "lengths = np.array([len(sent) for sent in train_sents])\n",
    "n_max_lengths = (lengths == MAX_LEN).sum()\n",
    "print('N with max lengths:', n_max_lengths)\n",
    "print('Ratio:', n_max_lengths / lengths.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vals = ['B', 'I', 'O', 'X', '[CLS]', '[SEP]']\n",
    "tag2idx = {t : i for i, t in enumerate(tags_vals)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids, train_tags, train_attention_masks = create_tensors(bpe_tokenizer, tag2idx, \n",
    "                                                                    train_sents, train_labels, MAX_LEN)\n",
    "test_input_ids, test_tags, test_attention_masks = create_tensors(bpe_tokenizer, tag2idx, \n",
    "                                                                 test_sents, test_labels, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_optimizer(tag2idx, full_finetuning=True):\n",
    "    model = BertForTokenClassification.from_pretrained('bert-base-cased', \n",
    "                                                       cache_dir=CACHE_DIR, \n",
    "                                                       num_labels=len(tag2idx))\n",
    "    model.cuda()\n",
    "    \n",
    "    #lr_head = 5e-4\n",
    "    lr_head = 5e-2\n",
    "    lr_body = 5e-5\n",
    "    weight_decay = 0.01\n",
    "    \n",
    "    no_decay = ['bias', 'gamma', 'beta']\n",
    "\n",
    "    logger.info(f'Full finetuning: {full_finetuning}')\n",
    "    if full_finetuning:\n",
    "        param_optimizer = list(model.bert.named_parameters())\n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params': [p for n, p in param_optimizer \n",
    "                        if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': weight_decay},\n",
    "            {'params': [p for n, p in param_optimizer \n",
    "                        if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.0},\n",
    "            {'params' : [p for n, p in model.classifier.named_parameters()\n",
    "                         if not any(nd in n for nd in no_decay)],\n",
    "             'lr' : lr_head,\n",
    "             'weight_decay': weight_decay},\n",
    "            {'params' : [p for n, p in model.classifier.named_parameters()\n",
    "                        if any(nd in n for nd in no_decay)],\n",
    "             'lr' : lr_head,\n",
    "             'weight_decay' : 0.0\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        n_params = sum(p.numel() for p in model.parameters())\n",
    "    else:\n",
    "        param_optimizer = list(model.classifier.named_parameters()) \n",
    "        optimizer_grouped_parameters = [\n",
    "            {'params' : [p for n, p in param_optimizer\n",
    "                         if not any(nd in n for nd in no_decay)],\n",
    "             'lr' : lr_head,\n",
    "             'weight_decay': weight_decay},\n",
    "            {'params' : [p for n, p in param_optimizer\n",
    "                         if any(nd in n for nd in no_decay)],\n",
    "             'lr' : lr_head,\n",
    "             'weight_decay' : 0.0\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "        n_params = sum(p.numel() for p in model.classifier.parameters())\n",
    "        \n",
    "    logger.info(f'N parameters: {n_params}')\n",
    "\n",
    "    optimizer = BertAdam(optimizer_grouped_parameters, lr=lr_body)\n",
    "    #lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.95)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7)\n",
    "    \n",
    "    return model, optimizer, lr_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from i2b2_utils import subsample_dataset\n",
    "# Only for CAD and Diabetes\n",
    "train_input_ids, train_tags, train_attention_masks = subsample_dataset(train_input_ids, train_tags, \n",
    "                                                                       train_attention_masks, \n",
    "                                                                       positive_tag=tag2idx['B'], \n",
    "                                                                       negative_ratio=0.2, positive_ratio=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-26 07:32:17,214 - active_learning - INFO - Creating model...\n",
      "2019-06-26 07:32:25,645 - active_learning - INFO - Full finetuning: True\n",
      "2019-06-26 07:32:25,649 - active_learning - INFO - N parameters: 108314886\n",
      "2019-06-26 07:32:25,651 - active_learning - INFO - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-26 07:32:59,140 - active_learning - INFO - Train loss: 0.17447211174294353\n",
      "2019-06-26 07:33:03,340 - active_learning - INFO - Validation loss: 0.06728626787662506\n",
      "2019-06-26 07:33:03,697 - active_learning - INFO - Validation F1-Score: 0.6149982059562255\n",
      "2019-06-26 07:33:03,730 - active_learning - INFO - Validatin accuracy: 0.9896332050104547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 1/5 [00:38<02:32, 38.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-26 07:33:37,241 - active_learning - INFO - Train loss: 0.011551058506630662\n",
      "2019-06-26 07:33:41,245 - active_learning - INFO - Validation loss: 0.023718425072729588\n",
      "2019-06-26 07:33:41,598 - active_learning - INFO - Validation F1-Score: 0.8019323671497585\n",
      "2019-06-26 07:33:41,630 - active_learning - INFO - Validatin accuracy: 0.9963066460828953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|████      | 2/5 [01:15<01:54, 38.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-26 07:34:15,254 - active_learning - INFO - Train loss: 0.0032609287056050472\n",
      "2019-06-26 07:34:19,262 - active_learning - INFO - Validation loss: 0.026211214251816273\n",
      "2019-06-26 07:34:19,624 - active_learning - INFO - Validation F1-Score: 0.8158035237586759\n",
      "2019-06-26 07:34:19,656 - active_learning - INFO - Validatin accuracy: 0.9964825200789479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|██████    | 3/5 [01:54<01:16, 38.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-26 07:34:53,319 - active_learning - INFO - Train loss: 0.0011852914756731948\n",
      "2019-06-26 07:34:57,337 - active_learning - INFO - Validation loss: 0.025049280375242233\n",
      "2019-06-26 07:34:57,698 - active_learning - INFO - Validation F1-Score: 0.8109756097560976\n",
      "2019-06-26 07:34:57,731 - active_learning - INFO - Validatin accuracy: 0.9962675629726614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|████████  | 4/5 [02:32<00:38, 38.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-06-26 07:35:31,443 - active_learning - INFO - Train loss: 0.0008036139156942109\n",
      "2019-06-26 07:35:35,465 - active_learning - INFO - Validation loss: 0.02563057281076908\n",
      "2019-06-26 07:35:35,823 - active_learning - INFO - Validation F1-Score: 0.8183694530443757\n",
      "2019-06-26 07:35:35,856 - active_learning - INFO - Validatin accuracy: 0.9964825200789479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 5/5 [03:10<00:00, 38.07s/it]\n"
     ]
    }
   ],
   "source": [
    "logger.info('Creating model...')\n",
    "model, optimizer, lr_scheduler = create_model_optimizer(tag2idx, full_finetuning=True)\n",
    "logger.info('Done.')\n",
    "\n",
    "t_tr_inputs = torch.tensor(train_input_ids)\n",
    "t_tr_tags = torch.tensor(train_tags)\n",
    "t_tr_masks = torch.tensor(train_attention_masks)\n",
    "\n",
    "t_val_inputs = torch.tensor(test_input_ids)\n",
    "t_val_tags = torch.tensor(test_tags)\n",
    "t_val_masks = torch.tensor(test_attention_masks)\n",
    "\n",
    "train_data = TensorDataset(t_tr_inputs, t_tr_masks, t_tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, \n",
    "                              batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_data = TensorDataset(t_val_inputs, t_val_masks, t_val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, \n",
    "                              batch_size=PRED_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train(model, optimizer, lr_scheduler, train_dataloader, valid_dataloader, \n",
    "      epochs=5, device=device, tags_vals=tags_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.9835164835164835\n",
      "Precision:  0.8647342995169082\n",
      "F1: 0.9203084832904884\n"
     ]
    }
   ],
   "source": [
    "from i2b2_utils import evaluation_level_document, annotate_text \n",
    "\n",
    "pred_tags = annotate_text(model, valid_dataloader)\n",
    "pos, pred_pos, tp = evaluation_level_document(pred_tags, test_selected_dataset, attr_name, tag2idx)\n",
    "\n",
    "recall = tp / pos\n",
    "precision = tp / pred_pos\n",
    "f1 = 2. * recall * precision / (recall + precision)\n",
    "\n",
    "print('Recall: ', recall)\n",
    "print('Precision: ', precision)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 epochs\n",
    "'I-ORG':\n",
    "Recall:  0.968944099378882\n",
    "Precision:  0.8342245989304813\n",
    "F1: 0.896551724137931"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 epochs\n",
    "'I-PERS':\n",
    "Recall:  1.0\n",
    "Precision:  0.8743169398907104\n",
    "F1: 0.9329446064139941"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 epochs\n",
    "'I_MISC'\n",
    "Recall:  1.0\n",
    "Precision:  0.946078431372549\n",
    "F1: 0.9722921914357683"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5 epochs\n",
    "'I_MISC' \n",
    "Recall:  0.9835164835164835\n",
    "Precision:  0.8647342995169082\n",
    "F1: 0.9203084832904884"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
