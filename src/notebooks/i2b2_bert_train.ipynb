{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla V100-DGXS-16GB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device('cuda')\n",
    "n_gpu = torch.cuda.device_count()\n",
    "\n",
    "for i in range(n_gpu):\n",
    "    print(torch.cuda.get_device_name(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('biomed_ie')\n",
    "\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "fhandler = logging.FileHandler(filename='../workdir/i2b2_active_learning.log', mode='a')\n",
    "fhandler.setFormatter(formatter)\n",
    "logger.addHandler(fhandler)\n",
    "\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setFormatter(formatter)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_DIR = '../workdir/models/0.4.0'\n",
    "\n",
    "#MAX_LEN = 100\n",
    "MAX_LEN = 100\n",
    "#BATCH_SIZE = 105\n",
    "BATCH_SIZE = 45 \n",
    "# MAX_LEN = 150\n",
    "# BATCH_SIZE = 32\n",
    "PRED_BATCH_SIZE = 600\n",
    "random_state = 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex.\n"
     ]
    }
   ],
   "source": [
    "from i2b2_utils import drop_noise_samples, split_train_test_by_document\n",
    "from bert_utils import train, test, create_model_optimizer, tokenize_and_generate_labels, to_torch_tensors, create_tensors\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#from pytorch_transformers import BertTokenizer, BertConfig\n",
    "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(46635, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HYPERTENSION</th>\n",
       "      <th>CAD</th>\n",
       "      <th>DIABETES</th>\n",
       "      <th>texts</th>\n",
       "      <th>doc_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>Record date: 2154-07-21\\n\\n\\n\\tCARDIOLOGY\\n\\t\\...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>D.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[[24, 36]]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>She has well-controlled hypertension on stable...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>a.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>SOCIAL HISTORY, FAMILY HISTORY, AND REVIEW OF ...</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HYPERTENSION CAD DIABETES  \\\n",
       "0              []  []       []   \n",
       "1              []  []       []   \n",
       "10     [[24, 36]]  []       []   \n",
       "100            []  []       []   \n",
       "1000           []  []       []   \n",
       "\n",
       "                                                  texts  doc_ids  \n",
       "0     Record date: 2154-07-21\\n\\n\\n\\tCARDIOLOGY\\n\\t\\...        0  \n",
       "1                                                    D.        0  \n",
       "10    She has well-controlled hypertension on stable...        0  \n",
       "100                                                  a.        1  \n",
       "1000  SOCIAL HISTORY, FAMILY HISTORY, AND REVIEW OF ...       18  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path = '../workdir/i2b2/i2b2_training.json'\n",
    "dataset = pd.read_json(dataset_path)\n",
    "print(dataset.shape)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9871, 5)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_name = 'HYPERTENSION'\n",
    "#attr_name = 'CAD'\n",
    "#attr_name = 'DIABETES'\n",
    "\n",
    "selected_dataset = drop_noise_samples(dataset, attr_name)\n",
    "selected_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30208, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test_path = '../workdir/i2b2/i2b2_testing.json'\n",
    "dataset_test = pd.read_json(dataset_test_path)\n",
    "dataset_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train (9871, 5)\n",
      "test (6813, 5)\n"
     ]
    }
   ],
   "source": [
    "test_selected_dataset = drop_noise_samples(dataset_test, attr_name)\n",
    "train_selected_dataset = selected_dataset\n",
    "print('train', selected_dataset.shape)\n",
    "print('test', test_selected_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare model and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from isanlp.en.processor_tokenizer_nltk_en import ProcessorTokenizerNltkEn\n",
    "\n",
    "word_tokenizer = ProcessorTokenizerNltkEn()\n",
    "bpe_tokenizer = BertTokenizer.from_pretrained('bert-base-cased', cache_dir=CACHE_DIR, do_lower_case=False)\n",
    "train_sents, train_labels = tokenize_and_generate_labels(word_tokenizer, bpe_tokenizer, train_selected_dataset, attr_name, MAX_LEN)\n",
    "test_sents, test_labels = tokenize_and_generate_labels(word_tokenizer, bpe_tokenizer, test_selected_dataset, attr_name, MAX_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N with max lengths: 381\n",
      "Ratio: 0.03859791307871543\n"
     ]
    }
   ],
   "source": [
    "lengths = np.array([len(sent) for sent in train_sents])\n",
    "n_max_lengths = (lengths == MAX_LEN).sum()\n",
    "print('N with max lengths:', n_max_lengths)\n",
    "print('Ratio:', n_max_lengths / lengths.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags_vals = ['B', 'I', 'O', 'X', '[CLS]', '[SEP]']\n",
    "tag2idx = {t : i for i, t in enumerate(tags_vals)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input_ids,train_attention_masks, train_tags = create_tensors(bpe_tokenizer, tag2idx, \n",
    "                                                                    train_sents, train_labels, MAX_LEN)\n",
    "test_input_ids, test_attention_masks, test_tags = create_tensors(bpe_tokenizer, tag2idx, \n",
    "                                                                 test_sents, test_labels, MAX_LEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from i2b2_utils import subsample_dataset\n",
    "# Only for CAD and Diabetes\n",
    "train_input_ids, train_tags, train_attention_masks = subsample_dataset(train_input_ids, train_tags, \n",
    "                                                                       train_attention_masks, \n",
    "                                                                       positive_tag=tag2idx['B'], \n",
    "                                                                       negative_ratio=0.5, positive_ratio=1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 14:32:29,784 - biomed_ie - INFO - Creating model...\n",
      "2019-08-11 14:32:46,204 - biomed_ie - INFO - Full finetuning: True\n",
      "2019-08-11 14:32:46,208 - biomed_ie - INFO - N parameters: 108314886\n",
      "2019-08-11 14:32:46,209 - biomed_ie - INFO - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 14:34:05,131 - biomed_ie - INFO - Train loss: 2.4389469706056364e-05\n",
      "2019-08-11 14:34:17,770 - biomed_ie - INFO - Validation loss: 2.742502970673978e-07\n",
      "2019-08-11 14:34:22,337 - biomed_ie - INFO - Validation F1-Score: 0.6705882352941176\n",
      "2019-08-11 14:34:22,338 - biomed_ie - INFO - Validation accuracy: 0.9987509778105413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   5%|▌         | 1/20 [01:36<30:26, 96.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 14:35:41,157 - biomed_ie - INFO - Train loss: 3.4065052729973288e-06\n",
      "2019-08-11 14:35:53,792 - biomed_ie - INFO - Validation loss: 2.1278160450146412e-07\n",
      "2019-08-11 14:35:58,327 - biomed_ie - INFO - Validation F1-Score: 0.7181978798586572\n",
      "2019-08-11 14:35:58,328 - biomed_ie - INFO - Validation accuracy: 0.9990664524872603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  10%|█         | 2/20 [03:12<28:49, 96.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 14:37:18,507 - biomed_ie - INFO - Train loss: 2.3676043060231826e-06\n",
      "2019-08-11 14:37:31,156 - biomed_ie - INFO - Validation loss: 2.3649169305127434e-07\n",
      "2019-08-11 14:37:35,700 - biomed_ie - INFO - Validation F1-Score: 0.7286084701815038\n",
      "2019-08-11 14:37:35,701 - biomed_ie - INFO - Validation accuracy: 0.9989038864548694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  15%|█▌        | 3/20 [04:49<27:19, 96.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 14:38:55,767 - biomed_ie - INFO - Train loss: 1.7079229652016948e-06\n",
      "2019-08-11 14:39:08,433 - biomed_ie - INFO - Validation loss: 2.633134165030893e-07\n",
      "2019-08-11 14:39:12,957 - biomed_ie - INFO - Validation F1-Score: 0.7124183006535947\n",
      "2019-08-11 14:39:12,958 - biomed_ie - INFO - Validation accuracy: 0.9988250177856897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|██        | 4/20 [06:26<25:47, 96.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-11 14:40:32,445 - biomed_ie - INFO - Train loss: 1.3385674212699562e-06\n",
      "2019-08-11 14:40:45,105 - biomed_ie - INFO - Validation loss: 2.549370564108908e-07\n",
      "2019-08-11 14:40:49,637 - biomed_ie - INFO - Validation F1-Score: 0.7431072210065645\n",
      "2019-08-11 14:40:49,638 - biomed_ie - INFO - Validation accuracy: 0.9990922055220945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  25%|██▌       | 5/20 [08:03<24:10, 96.70s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-6ce3d21bfbfb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m train(model, optimizer, lr_scheduler, train_dataloader, valid_dataloader, \n\u001b[0;32m---> 26\u001b[0;31m       epochs=20, device=device, tags_vals=tags_vals)\n\u001b[0m",
      "\u001b[0;32m/notebook/projects/biomed_ie/src/bert_utils.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, lr_scheduler, train_dataloader, valid_dataloader, epochs, device, tags_vals, early_stopping, max_grad_norm)\u001b[0m\n\u001b[1;32m    160\u001b[0m             loss = model(b_input_ids, token_type_ids=None,\n\u001b[1;32m    161\u001b[0m                          attention_mask=b_input_mask, labels=b_labels)\n\u001b[0;32m--> 162\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \"\"\"\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.7/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "logger.info('Creating model...')\n",
    "torch.cuda.empty_cache()\n",
    "#model, optimizer, lr_scheduler = create_model_optimizer(tag2idx, full_finetuning=True, base_lr=5e-4)\n",
    "model, optimizer, lr_scheduler = create_model_optimizer(tag2idx, cache_dir=CACHE_DIR, full_finetuning=True, base_lr=5e-5)\n",
    "logger.info('Done.')\n",
    "\n",
    "t_tr_inputs = torch.tensor(train_input_ids)\n",
    "t_tr_tags = torch.tensor(train_tags)\n",
    "t_tr_masks = torch.tensor(train_attention_masks)\n",
    "\n",
    "t_val_inputs = torch.tensor(test_input_ids)\n",
    "t_val_tags = torch.tensor(test_tags)\n",
    "t_val_masks = torch.tensor(test_attention_masks)\n",
    "\n",
    "train_data = TensorDataset(t_tr_inputs, t_tr_masks, t_tr_tags)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, \n",
    "                              batch_size=BATCH_SIZE)\n",
    "\n",
    "valid_data = TensorDataset(t_val_inputs, t_val_masks, t_val_tags)\n",
    "valid_sampler = SequentialSampler(valid_data)\n",
    "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, \n",
    "                              batch_size=PRED_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "train(model, optimizer, lr_scheduler, train_dataloader, valid_dataloader, \n",
    "      epochs=20, device=device, tags_vals=tags_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pytorch-pretrained-bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytorch-pretrained-bert==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from i2b2_utils import evaluation_level_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "\n",
    "def flair_process_i2b2(model, dataset, attr_name):\n",
    "    res = model.predict([Sentence(t) for t in dataset.texts])\n",
    "    res = [[e.tags[attr_name].value for e in sent] for sent in res]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-06 15:53:14,376 loading file ../models/new/CAD//elmo-pubmed/1.0/best-model.pt\n"
     ]
    }
   ],
   "source": [
    "#model = SequenceTagger.load('../models/new/DIABETES/fasttext/1.0/best-model.pt')\n",
    "#model = SequenceTagger.load('../models/new/HYPERTENSION//elmo-pubmed/1.0/best-model.pt')\n",
    "model = SequenceTagger.load('../models/new/CAD//elmo-pubmed/1.0/best-model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'evaluation_level_document' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0444f738fd6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mflair_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mflair_process_i2b2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_selected_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation_level_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflair_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_selected_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'evaluation_level_document' is not defined"
     ]
    }
   ],
   "source": [
    "flair_results = flair_process_i2b2(model, test_selected_dataset, attr_name)\n",
    "pos, pred_pos, tp = evaluation_level_document(flair_results, test_selected_dataset, attr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos, pred_pos, tp = evaluation_level_document(flair_results, test_selected_dataset, attr_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid_dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-9a98a2dacce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mi2b2_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mannotate_text\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpred_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mannotate_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_pos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation_level_document\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_selected_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtag2idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid_dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "# For bert\n",
    "from i2b2_utils import annotate_text \n",
    "\n",
    "pred_tags = annotate_text(model, valid_dataloader)\n",
    "pos, pred_pos, tp = evaluation_level_document(pred_tags, test_selected_dataset, attr_name, tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  1.0\n",
      "Precision:  0.4377431906614786\n",
      "F1: 0.6089309878213802\n"
     ]
    }
   ],
   "source": [
    "recall = tp / pos\n",
    "precision = tp / pred_pos\n",
    "f1 = 2. * recall * precision / (recall + precision)\n",
    "\n",
    "print('Recall: ', recall)\n",
    "print('Precision: ', precision)\n",
    "print('F1:', f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hypertension:\n",
    "Recall:  0.9719387755102041\n",
    "Precision:  0.9645569620253165\n",
    "F1: 0.9682337992376113"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAD:\n",
    "Recall:  0.9511111111111111\n",
    "Precision:  0.6793650793650794\n",
    "F1: 0.7925925925925925"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diabetes:\n",
    "Recall:  0.9667590027700831\n",
    "Precision:  0.8790931989924433\n",
    "F1: 0.9208443271767809"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
